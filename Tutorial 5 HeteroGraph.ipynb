{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = {\n",
    "  ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
    "   ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
    "    ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('drug', 'interacts', 'drug'): (tensor([0, 1]), tensor([1, 2])),\n",
       " ('drug', 'interacts', 'gene'): (tensor([0, 1]), tensor([2, 3])),\n",
       " ('drug', 'treats', 'disease'): (tensor([1]), tensor([2]))}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.heterograph(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disease', 'drug', 'gene']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ntypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interacts', 'interacts', 'treats']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drug', 'interacts', 'drug'),\n",
       " ('drug', 'interacts', 'gene'),\n",
       " ('drug', 'treats', 'disease')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.canonical_etypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A homogeneous graph**\n",
    "\n",
    "dgl.heterograph({('node_type', 'edge_type', 'node_type'): (u, v)})\n",
    "\n",
    "**A bipartite graph**\n",
    "\n",
    "dgl.heterograph({('source_type', 'edge_type', 'destination_type'): (u, v)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'disease': 3, 'drug': 3, 'gene': 4},\n",
       "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 1},\n",
       "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'gene', 'interacts'), ('drug', 'disease', 'treats')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutMultiEdgeDataView([('drug', 'drug'), ('drug', 'gene'), ('drug', 'disease')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.metagraph().edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of all nodes in the graph\n",
    "g.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of drug nodes\n",
    "g.num_nodes('drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Node type name must be specified if there are more than one node types.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c5fe01d28769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Nodes of different types have separate IDs, hence not well-defined without a type specified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\view.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, ntype)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;34m\"\"\"Return the nodes.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mntid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typeid_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         return F.copy_to(F.arange(0, self._graph._graph.number_of_nodes(ntid),\n\u001b[0;32m     44\u001b[0m                                   dtype=self._graph.idtype),\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mget_ntype_id\u001b[1;34m(self, ntype)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unibipartite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_srctypes_invmap\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1072\u001b[1;33m                 raise DGLError('Node type name must be specified if there are more than one '\n\u001b[0m\u001b[0;32m   1073\u001b[0m                                'node types.')\n\u001b[0;32m   1074\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDGLError\u001b[0m: Node type name must be specified if there are more than one node types."
     ]
    }
   ],
   "source": [
    "# Nodes of different types have separate IDs, hence not well-defined without a type specified\n",
    "g.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " g.nodes('drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set/get features for a specific node/edge type, DGL provides two new types of syntax – g.nodes[‘node_type’].data[‘feat_name’] and g.edges[‘edge_type’].data[‘feat_name’]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set/get feature 'hv' for nodes of type 'drug'\n",
    "g.nodes['drug'].data['hv'] = th.ones(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['drug'].data['hv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set/get feature 'he' for edge of type 'treats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges['treats'].data['he'] = th.zeros(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges['treats'].data['he']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Edge type Subgraph </h4>\n",
    "Retain relations ('drug', 'interacts', 'drug') and ('drug', 'treats', 'disease'). \n",
    "All nodes for 'drug' and 'disease' will be retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = dgl.edge_type_subgraph(g, [('drug', 'interacts', 'drug'),\n",
    "                         ('drug', 'treats', 'disease')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'disease': 3, 'drug': 3},\n",
       "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'treats', 'disease'): 1},\n",
       "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'disease', 'treats')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.nodes['drug'].data['hv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterographs provide a clean interface for managing nodes/edges of different types and their associated features. \n",
    "This is particularly helpful when:\n",
    "\n",
    "    The features for nodes/edges of different types have different data types or sizes.\n",
    "\n",
    "    We want to apply different operations to nodes/edges of different types.\n",
    "    \n",
    "If the above conditions do not hold and one does not want to distinguish node/edge types in modeling, then DGL allows converting a heterogeneous graph to a homogeneous graph with dgl.DGLGraph.to_homogeneous() API. It proceeds as follows:\n",
    "\n",
    "    Relabels nodes/edges of all types using consecutive integers starting from 0\n",
    "\n",
    "    Merges the features across node/edge types specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.heterograph({\n",
    "...    ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
    "...    ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'disease': 3, 'drug': 3},\n",
       "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'treats', 'disease'): 1},\n",
       "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'disease', 'treats')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['drug'].data['hv'] = th.zeros(3, 1)\n",
    "g.nodes['disease'].data['hv'] = th.ones(3, 1)\n",
    "g.edges['interacts'].data['he'] = th.zeros(2, 1)\n",
    "g.edges['treats'].data['he'] = th.zeros(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, it does not merge any features\n",
    "hg = dgl.to_homogeneous(g)\n",
    "'hv' in hg.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_TYPE': tensor([0, 0, 0, 1, 1, 1]), '_ID': tensor([0, 1, 2, 0, 1, 2])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.ndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy edge features\n",
    "For feature copy, it expects features to have  the same size and dtype across node/edge types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Cannot concatenate column he with shape Scheme(shape=(2,), dtype=torch.float32) and shape Scheme(shape=(1,), dtype=torch.float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d05c5be88834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_homogeneous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'he'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\convert.py\u001b[0m in \u001b[0;36mto_homogeneous\u001b[1;34m(G, ndata, edata)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0medata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[0mcomb_nf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m     \u001b[0mcomb_ef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_edge_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcomb_nf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mretg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomb_nf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mcombine_frames\u001b[1;34m(frames, ids, col_names)\u001b[0m\n\u001b[0;32m   5780\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschemes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5781\u001b[0m                     raise DGLError('Cannot concatenate column %s with shape %s and shape %s' %\n\u001b[1;32m-> 5782\u001b[1;33m                                    (key, frame.schemes[key], scheme))\n\u001b[0m\u001b[0;32m   5783\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5784\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mschemes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDGLError\u001b[0m: Cannot concatenate column he with shape Scheme(shape=(2,), dtype=torch.float32) and shape Scheme(shape=(1,), dtype=torch.float32)"
     ]
    }
   ],
   "source": [
    "hg = dgl.to_homogeneous(g, edata=['he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy node features\n",
    "hg = dgl.to_homogeneous(g, ndata=['hv'])\n",
    "hg.ndata['hv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Second Example from old code </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "\n",
    "ratings = dgl.heterograph(\n",
    "    {('user', '+1', 'movie') : (np.array([0, 0, 1]), np.array([0, 1, 0])),\n",
    "     ('user', '-1', 'movie') : (np.array([2]), np.array([1]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'movie': 2, 'user': 3},\n",
       "      num_edges={('user', '+1', 'movie'): 3, ('user', '-1', 'movie'): 1},\n",
       "      metagraph=[('user', 'movie', '+1'), ('user', 'movie', '-1')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Manipulating heterograph\n",
    "\n",
    "You can create a more realistic heterograph using the ACM dataset. To do this, first \n",
    "download the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import urllib.request\n",
    "\n",
    "# data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "# data_file_path = '/tmp/ACM.mat'\n",
    "\n",
    "# urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat('ACM.mat')\n",
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores node information by their types: ``P`` for paper, ``A``\n",
    " for author, ``C`` for conference, ``L`` for subject code, and so on. The relationships are stored as SciPy sparse matrix under key ``XvsY``, where ``X`` and ``Y`` could be any of the node type code.\n",
    "\n",
    "The following code prints out some statistics about the paper-author relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csc.csc_matrix'>\n",
      "#Papers: 12499\n",
      "#Authors: 17431\n",
      "#Links: 37055\n"
     ]
    }
   ],
   "source": [
    "print(type(data['PvsA']))\n",
    "print('#Papers:', data['PvsA'].shape[0])\n",
    "print('#Authors:', data['PvsA'].shape[1])\n",
    "print('#Links:', data['PvsA'].nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting this SciPy matrix to a heterograph in DGL is straightforward.\n",
    "\n",
    "pa_g = dgl.heterograph({('paper', 'written-by', 'author') : data['PvsA'].nonzero()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'author': 17431, 'paper': 12499},\n",
       "      num_edges={('paper', 'written-by', 'author'): 37055},\n",
       "      metagraph=[('paper', 'author', 'written-by')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node types: ['author', 'paper']\n",
      "Edge types: ['written-by']\n",
      "Canonical edge types: [('paper', 'written-by', 'author')]\n"
     ]
    }
   ],
   "source": [
    "# You can easily print out the type names and other structural information.\n",
    "\n",
    "print('Node types:', pa_g.ntypes)\n",
    "print('Edge types:', pa_g.etypes)\n",
    "print('Canonical edge types:', pa_g.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n"
     ]
    }
   ],
   "source": [
    "# Nodes and edges are assigned integer IDs starting from zero and each type has its own counting.\n",
    "# To distinguish the nodes and edges of different types, specify the type name as the argument.\n",
    "print(pa_g.number_of_nodes('paper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37055\n",
      "37055\n",
      "tensor([3532, 6421, 8516, 8560])\n"
     ]
    }
   ],
   "source": [
    "# Canonical edge type name can be shortened to only one edge type name if it is\n",
    "# uniquely distinguishable.\n",
    "print(pa_g.number_of_edges(('paper', 'written-by', 'author')))\n",
    "print(pa_g.number_of_edges('written-by'))\n",
    "print(pa_g.successors(1, etype='written-by'))  # get the authors that write paper #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37055\n"
     ]
    }
   ],
   "source": [
    "# Type name argument could be omitted whenever the behavior is unambiguous.\n",
    "print(pa_g.number_of_edges())  # Only one edge type, the edge type argument could be omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n",
      "30789\n",
      "tensor([1361, 2624, 8670, 9845])\n"
     ]
    }
   ],
   "source": [
    "# A homogeneous graph is just a special case of a heterograph with only one type\n",
    "# of node and edge.\n",
    "\n",
    "# Paper-citing-paper graph is a homogeneous graph\n",
    "pp_g = dgl.heterograph({('paper', 'citing', 'paper') : data['PvsP'].nonzero()})\n",
    "# equivalent (shorter) API for creating homogeneous graph\n",
    "pp_g = dgl.from_scipy(data['PvsP'])\n",
    "\n",
    "# All the ntype and etype arguments could be omitted because the behavior is unambiguous.\n",
    "print(pp_g.number_of_nodes())\n",
    "print(pp_g.number_of_edges())\n",
    "print(pp_g.successors(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_batch_num_edges',\n",
       " '_batch_num_nodes',\n",
       " '_canonical_etypes',\n",
       " '_dsttypes_invmap',\n",
       " '_edge_frames',\n",
       " '_etype2canonical',\n",
       " '_etypes',\n",
       " '_etypes_invmap',\n",
       " '_find_etypes',\n",
       " '_get_e_repr',\n",
       " '_get_n_repr',\n",
       " '_graph',\n",
       " '_idtype_str',\n",
       " '_init',\n",
       " '_is_unibipartite',\n",
       " '_node_frames',\n",
       " '_ntypes',\n",
       " '_pop_e_repr',\n",
       " '_pop_n_repr',\n",
       " '_reset_cached_info',\n",
       " '_set_e_repr',\n",
       " '_set_n_repr',\n",
       " '_srctypes_invmap',\n",
       " 'add_edge',\n",
       " 'add_edges',\n",
       " 'add_nodes',\n",
       " 'add_self_loop',\n",
       " 'adj',\n",
       " 'adjacency_matrix',\n",
       " 'adjacency_matrix_scipy',\n",
       " 'all_edges',\n",
       " 'apply_edges',\n",
       " 'apply_nodes',\n",
       " 'astype',\n",
       " 'batch_num_edges',\n",
       " 'batch_num_nodes',\n",
       " 'batch_size',\n",
       " 'canonical_etypes',\n",
       " 'clone',\n",
       " 'cpu',\n",
       " 'create_formats_',\n",
       " 'device',\n",
       " 'dstdata',\n",
       " 'dstnodes',\n",
       " 'dsttypes',\n",
       " 'edata',\n",
       " 'edge_attr_schemes',\n",
       " 'edge_id',\n",
       " 'edge_ids',\n",
       " 'edge_subgraph',\n",
       " 'edge_type_subgraph',\n",
       " 'edges',\n",
       " 'etypes',\n",
       " 'filter_edges',\n",
       " 'filter_nodes',\n",
       " 'find_edges',\n",
       " 'formats',\n",
       " 'from_networkx',\n",
       " 'from_scipy_sparse_matrix',\n",
       " 'get_etype_id',\n",
       " 'get_ntype_id',\n",
       " 'get_ntype_id_from_dst',\n",
       " 'get_ntype_id_from_src',\n",
       " 'group_apply_edges',\n",
       " 'has_edge_between',\n",
       " 'has_edges_between',\n",
       " 'has_node',\n",
       " 'has_nodes',\n",
       " 'idtype',\n",
       " 'in_degree',\n",
       " 'in_degrees',\n",
       " 'in_edges',\n",
       " 'in_subgraph',\n",
       " 'inc',\n",
       " 'incidence_matrix',\n",
       " 'int',\n",
       " 'is_block',\n",
       " 'is_homogeneous',\n",
       " 'is_multigraph',\n",
       " 'is_readonly',\n",
       " 'is_unibipartite',\n",
       " 'line_graph',\n",
       " 'local_scope',\n",
       " 'local_var',\n",
       " 'long',\n",
       " 'metagraph',\n",
       " 'multi_pull',\n",
       " 'multi_recv',\n",
       " 'multi_send_and_recv',\n",
       " 'multi_update_all',\n",
       " 'ndata',\n",
       " 'node_attr_schemes',\n",
       " 'node_type_subgraph',\n",
       " 'nodes',\n",
       " 'ntypes',\n",
       " 'num_dst_nodes',\n",
       " 'num_edges',\n",
       " 'num_nodes',\n",
       " 'num_src_nodes',\n",
       " 'number_of_dst_nodes',\n",
       " 'number_of_edges',\n",
       " 'number_of_nodes',\n",
       " 'number_of_src_nodes',\n",
       " 'out_degree',\n",
       " 'out_degrees',\n",
       " 'out_edges',\n",
       " 'out_subgraph',\n",
       " 'predecessors',\n",
       " 'prop_edges',\n",
       " 'prop_nodes',\n",
       " 'pull',\n",
       " 'push',\n",
       " 'readonly',\n",
       " 'recv',\n",
       " 'register_apply_edge_func',\n",
       " 'register_apply_node_func',\n",
       " 'register_message_func',\n",
       " 'register_reduce_func',\n",
       " 'remove_edges',\n",
       " 'remove_nodes',\n",
       " 'remove_self_loop',\n",
       " 'reverse',\n",
       " 'send',\n",
       " 'send_and_recv',\n",
       " 'set_batch_num_edges',\n",
       " 'set_batch_num_nodes',\n",
       " 'set_e_initializer',\n",
       " 'set_n_initializer',\n",
       " 'shared_memory',\n",
       " 'srcdata',\n",
       " 'srcnodes',\n",
       " 'srctypes',\n",
       " 'subgraph',\n",
       " 'successors',\n",
       " 'to',\n",
       " 'to_canonical_etype',\n",
       " 'to_networkx',\n",
       " 'to_simple',\n",
       " 'update_all']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pp_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12496, 12497, 12498])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.srcnodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2193,  2250,  2256,  ...,  8351,  8362, 12497]),\n",
       " tensor([    0,     0,     0,  ..., 12498, 12498, 12498]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2193, 2250, 2256, 2710, 2778, 3111, 3114, 3853, 3889, 3937, 4204, 4242,\n",
       "        5479, 5496])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.predecessors(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x238771b2888>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.metagraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n",
      "      num_edges={('author', 'writing', 'paper'): 37055, ('paper', 'cited', 'paper'): 30789, ('paper', 'citing', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('paper', 'written-by', 'author'): 37055, ('subject', 'has', 'paper'): 12499},\n",
      "      metagraph=[('author', 'paper', 'writing'), ('paper', 'paper', 'cited'), ('paper', 'paper', 'citing'), ('paper', 'subject', 'is-about'), ('paper', 'author', 'written-by'), ('subject', 'paper', 'has')])\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the ACM graph using the paper-author, paper-paper, \n",
    "# and paper-subject relationships.  Meanwhile, also add the reverse\n",
    "# relationship to prepare for the later sections.\n",
    "\n",
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'].nonzero(),\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose().nonzero(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'].nonzero(),\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose().nonzero(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'].nonzero(),\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose().nonzero(),\n",
    "    })\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_batch_num_edges',\n",
       " '_batch_num_nodes',\n",
       " '_canonical_etypes',\n",
       " '_dsttypes_invmap',\n",
       " '_edge_frames',\n",
       " '_etype2canonical',\n",
       " '_etypes',\n",
       " '_etypes_invmap',\n",
       " '_find_etypes',\n",
       " '_get_e_repr',\n",
       " '_get_n_repr',\n",
       " '_graph',\n",
       " '_idtype_str',\n",
       " '_init',\n",
       " '_is_unibipartite',\n",
       " '_node_frames',\n",
       " '_ntypes',\n",
       " '_pop_e_repr',\n",
       " '_pop_n_repr',\n",
       " '_reset_cached_info',\n",
       " '_set_e_repr',\n",
       " '_set_n_repr',\n",
       " '_srctypes_invmap',\n",
       " 'add_edge',\n",
       " 'add_edges',\n",
       " 'add_nodes',\n",
       " 'add_self_loop',\n",
       " 'adj',\n",
       " 'adjacency_matrix',\n",
       " 'adjacency_matrix_scipy',\n",
       " 'all_edges',\n",
       " 'apply_edges',\n",
       " 'apply_nodes',\n",
       " 'astype',\n",
       " 'batch_num_edges',\n",
       " 'batch_num_nodes',\n",
       " 'batch_size',\n",
       " 'canonical_etypes',\n",
       " 'clone',\n",
       " 'cpu',\n",
       " 'create_formats_',\n",
       " 'device',\n",
       " 'dstdata',\n",
       " 'dstnodes',\n",
       " 'dsttypes',\n",
       " 'edata',\n",
       " 'edge_attr_schemes',\n",
       " 'edge_id',\n",
       " 'edge_ids',\n",
       " 'edge_subgraph',\n",
       " 'edge_type_subgraph',\n",
       " 'edges',\n",
       " 'etypes',\n",
       " 'filter_edges',\n",
       " 'filter_nodes',\n",
       " 'find_edges',\n",
       " 'formats',\n",
       " 'from_networkx',\n",
       " 'from_scipy_sparse_matrix',\n",
       " 'get_etype_id',\n",
       " 'get_ntype_id',\n",
       " 'get_ntype_id_from_dst',\n",
       " 'get_ntype_id_from_src',\n",
       " 'group_apply_edges',\n",
       " 'has_edge_between',\n",
       " 'has_edges_between',\n",
       " 'has_node',\n",
       " 'has_nodes',\n",
       " 'idtype',\n",
       " 'in_degree',\n",
       " 'in_degrees',\n",
       " 'in_edges',\n",
       " 'in_subgraph',\n",
       " 'inc',\n",
       " 'incidence_matrix',\n",
       " 'int',\n",
       " 'is_block',\n",
       " 'is_homogeneous',\n",
       " 'is_multigraph',\n",
       " 'is_readonly',\n",
       " 'is_unibipartite',\n",
       " 'line_graph',\n",
       " 'local_scope',\n",
       " 'local_var',\n",
       " 'long',\n",
       " 'metagraph',\n",
       " 'multi_pull',\n",
       " 'multi_recv',\n",
       " 'multi_send_and_recv',\n",
       " 'multi_update_all',\n",
       " 'ndata',\n",
       " 'node_attr_schemes',\n",
       " 'node_type_subgraph',\n",
       " 'nodes',\n",
       " 'ntypes',\n",
       " 'num_dst_nodes',\n",
       " 'num_edges',\n",
       " 'num_nodes',\n",
       " 'num_src_nodes',\n",
       " 'number_of_dst_nodes',\n",
       " 'number_of_edges',\n",
       " 'number_of_nodes',\n",
       " 'number_of_src_nodes',\n",
       " 'out_degree',\n",
       " 'out_degrees',\n",
       " 'out_edges',\n",
       " 'out_subgraph',\n",
       " 'predecessors',\n",
       " 'prop_edges',\n",
       " 'prop_nodes',\n",
       " 'pull',\n",
       " 'push',\n",
       " 'readonly',\n",
       " 'recv',\n",
       " 'register_apply_edge_func',\n",
       " 'register_apply_node_func',\n",
       " 'register_message_func',\n",
       " 'register_reduce_func',\n",
       " 'remove_edges',\n",
       " 'remove_nodes',\n",
       " 'remove_self_loop',\n",
       " 'reverse',\n",
       " 'send',\n",
       " 'send_and_recv',\n",
       " 'set_batch_num_edges',\n",
       " 'set_batch_num_nodes',\n",
       " 'set_e_initializer',\n",
       " 'set_n_initializer',\n",
       " 'shared_memory',\n",
       " 'srcdata',\n",
       " 'srcnodes',\n",
       " 'srctypes',\n",
       " 'subgraph',\n",
       " 'successors',\n",
       " 'to',\n",
       " 'to_canonical_etype',\n",
       " 'to_networkx',\n",
       " 'to_simple',\n",
       " 'update_all']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygraphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-474595e3b329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpygraphviz\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpgv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'"
     ]
    }
   ],
   "source": [
    "import pygraphviz as pgv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning tasks associated with heterographs\n",
    "# -------------------------------------------\n",
    "# Some of the typical learning tasks that involve heterographs include:\n",
    "#\n",
    "# * *Node classification and regression* to predict the class of each node or\n",
    "#   estimate a value associated with it.\n",
    "#\n",
    "# * *Link prediction* to predict if there is an edge of a certain\n",
    "#   type between a pair of nodes, or predict which other nodes a particular\n",
    "#   node is connected with (and optionally the edge types of such connections).\n",
    "#\n",
    "# * *Graph classification/regression* to assign an entire\n",
    "#   heterograph into one of the target classes or to estimate a numerical\n",
    "#   value associated with it.\n",
    "#\n",
    "# In this tutorial, we designed a simple example for the first task.\n",
    "#\n",
    "# A semi-supervised node classification example\n",
    "\n",
    "# Our goal is to predict the publishing conference of a paper using the ACM\n",
    "# academic graph we just created. To further simplify the task, we only focus\n",
    "# on papers published in three conferences: *KDD*, *ICML*, and *VLDB*. All\n",
    "# the other papers are not labeled, making it a semi-supervised setting.\n",
    "#\n",
    "# The following code extracts those papers from the raw dataset and prepares \n",
    "# the training, validation, testing split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pvc = data['PvsC'].tocsr()\n",
    "# find all papers published in KDD, ICML, VLDB\n",
    "c_selected = [0, 11, 13]  # KDD, ICML, VLDB\n",
    "p_selected = pvc[:, c_selected].tocoo()\n",
    "# generate labels\n",
    "labels = pvc.indices\n",
    "labels[labels == 11] = 1\n",
    "labels[labels == 13] = 2\n",
    "labels = torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train/val/test split\n",
    "pid = p_selected.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:800]).long()\n",
    "val_idx = torch.tensor(shuffle[800:900]).long()\n",
    "test_idx = torch.tensor(shuffle[900:]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12499])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__array_priority__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__idiv__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmatmul__',\n",
       " '__rmul__',\n",
       " '__round__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '_add_dense',\n",
       " '_add_sparse',\n",
       " '_arg_min_or_max',\n",
       " '_arg_min_or_max_axis',\n",
       " '_asindices',\n",
       " '_binopt',\n",
       " '_cs_matrix__get_has_canonical_format',\n",
       " '_cs_matrix__get_sorted',\n",
       " '_cs_matrix__set_has_canonical_format',\n",
       " '_cs_matrix__set_sorted',\n",
       " '_deduped_data',\n",
       " '_divide',\n",
       " '_divide_sparse',\n",
       " '_get_arrayXarray',\n",
       " '_get_arrayXint',\n",
       " '_get_arrayXslice',\n",
       " '_get_columnXarray',\n",
       " '_get_dtype',\n",
       " '_get_intXarray',\n",
       " '_get_intXint',\n",
       " '_get_intXslice',\n",
       " '_get_sliceXarray',\n",
       " '_get_sliceXint',\n",
       " '_get_sliceXslice',\n",
       " '_get_submatrix',\n",
       " '_has_sorted_indices',\n",
       " '_imag',\n",
       " '_inequality',\n",
       " '_insert_many',\n",
       " '_major_index_fancy',\n",
       " '_major_slice',\n",
       " '_maximum_minimum',\n",
       " '_min_or_max',\n",
       " '_min_or_max_axis',\n",
       " '_minor_index_fancy',\n",
       " '_minor_reduce',\n",
       " '_minor_slice',\n",
       " '_mul_multivector',\n",
       " '_mul_scalar',\n",
       " '_mul_sparse_matrix',\n",
       " '_mul_vector',\n",
       " '_prepare_indices',\n",
       " '_process_toarray_args',\n",
       " '_real',\n",
       " '_rsub_dense',\n",
       " '_scalar_binopt',\n",
       " '_set_arrayXarray',\n",
       " '_set_arrayXarray_sparse',\n",
       " '_set_dtype',\n",
       " '_set_intXint',\n",
       " '_set_many',\n",
       " '_set_self',\n",
       " '_setdiag',\n",
       " '_shape',\n",
       " '_sub_dense',\n",
       " '_sub_sparse',\n",
       " '_swap',\n",
       " '_validate_indices',\n",
       " '_with_data',\n",
       " '_zero_many',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctanh',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'asformat',\n",
       " 'asfptype',\n",
       " 'astype',\n",
       " 'ceil',\n",
       " 'check_format',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'count_nonzero',\n",
       " 'data',\n",
       " 'deg2rad',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'eliminate_zeros',\n",
       " 'expm1',\n",
       " 'floor',\n",
       " 'format',\n",
       " 'getH',\n",
       " 'get_shape',\n",
       " 'getcol',\n",
       " 'getformat',\n",
       " 'getmaxprint',\n",
       " 'getnnz',\n",
       " 'getrow',\n",
       " 'has_canonical_format',\n",
       " 'has_sorted_indices',\n",
       " 'indices',\n",
       " 'indptr',\n",
       " 'log1p',\n",
       " 'max',\n",
       " 'maximum',\n",
       " 'maxprint',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'nnz',\n",
       " 'nonzero',\n",
       " 'power',\n",
       " 'prune',\n",
       " 'rad2deg',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'rint',\n",
       " 'set_shape',\n",
       " 'setdiag',\n",
       " 'shape',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'sort_indices',\n",
       " 'sorted_indices',\n",
       " 'sqrt',\n",
       " 'sum',\n",
       " 'sum_duplicates',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'toarray',\n",
       " 'tobsr',\n",
       " 'tocoo',\n",
       " 'tocsc',\n",
       " 'tocsr',\n",
       " 'todense',\n",
       " 'todia',\n",
       " 'todok',\n",
       " 'tolil',\n",
       " 'transpose',\n",
       " 'trunc']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12499x14 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12499 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_selected1 = pvc.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12499x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2094 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12499x14 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12499 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvc.todok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12496, 12497, 12498])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.dstnodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12496, 12497, 12498])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.dstnodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12496, 12497, 12498])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_g.dstnodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5998, 10805,  8518,  ...,  8500, 10745,  7262])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Relational-GCN on heterograph</h3>\n",
    "\n",
    "We use `Relational-GCN <https://arxiv.org/abs/1703.06103>`_ to learn the\n",
    " representation of nodes in the graph. Its message-passing equation is as\n",
    " follows:\n",
    "\n",
    " $   h_i^{(l+1)} = \\sigma\\left(\\sum_{r\\in \\mathcal{R}}\n",
    "    \\sum_{j\\in\\mathcal{N}_r(i)}W_r^{(l)}h_j^{(l)}\\right)$\n",
    "\n",
    " Breaking down the equation, you see that there are two parts in the\n",
    " computation.\n",
    "\n",
    " (i) Message computation and aggregation within each relation :math:`r`\n",
    "\n",
    " (ii) Reduction that merges the results from multiple relationships\n",
    "\n",
    " Following this intuition, perform message passing on a heterograph in\n",
    " two steps.\n",
    "\n",
    " (i) Per-edge-type message passing\n",
    "\n",
    " (ii) Type wise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple GNN by stacking two ``HeteroRGCNLayer``. Since the\n",
    "# nodes do not have input features, make their embeddings trainable.\n",
    "\n",
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # Use trainable node embeddings as featureless inputs.\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        # get paper logits\n",
    "        return h_dict['paper']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.1476, Train Acc 0.2825, Val Acc 0.2600 (Best 0.2600), Test Acc 0.2764 (Best 0.2764)\n",
      "Loss 0.9114, Train Acc 0.5075, Val Acc 0.4700 (Best 0.5100), Test Acc 0.5092 (Best 0.5544)\n",
      "Loss 0.7546, Train Acc 0.5512, Val Acc 0.4700 (Best 0.5100), Test Acc 0.5117 (Best 0.5544)\n",
      "Loss 0.5548, Train Acc 0.7550, Val Acc 0.6400 (Best 0.6400), Test Acc 0.6759 (Best 0.6759)\n",
      "Loss 0.3889, Train Acc 0.9137, Val Acc 0.6600 (Best 0.6600), Test Acc 0.7127 (Best 0.7127)\n",
      "Loss 0.2679, Train Acc 0.9613, Val Acc 0.7100 (Best 0.7100), Test Acc 0.7680 (Best 0.7680)\n",
      "Loss 0.1778, Train Acc 0.9862, Val Acc 0.7500 (Best 0.7500), Test Acc 0.7688 (Best 0.7688)\n",
      "Loss 0.1189, Train Acc 0.9937, Val Acc 0.7500 (Best 0.7600), Test Acc 0.7730 (Best 0.7714)\n",
      "Loss 0.0821, Train Acc 0.9950, Val Acc 0.7400 (Best 0.7600), Test Acc 0.7596 (Best 0.7714)\n",
      "Loss 0.0587, Train Acc 0.9987, Val Acc 0.7200 (Best 0.7600), Test Acc 0.7588 (Best 0.7714)\n",
      "Loss 0.0441, Train Acc 1.0000, Val Acc 0.7300 (Best 0.7600), Test Acc 0.7613 (Best 0.7714)\n",
      "Loss 0.0354, Train Acc 1.0000, Val Acc 0.7600 (Best 0.7600), Test Acc 0.7546 (Best 0.7714)\n",
      "Loss 0.0295, Train Acc 1.0000, Val Acc 0.7700 (Best 0.7700), Test Acc 0.7554 (Best 0.7571)\n",
      "Loss 0.0255, Train Acc 1.0000, Val Acc 0.7600 (Best 0.7700), Test Acc 0.7580 (Best 0.7571)\n",
      "Loss 0.0226, Train Acc 1.0000, Val Acc 0.7700 (Best 0.7700), Test Acc 0.7596 (Best 0.7571)\n",
      "Loss 0.0203, Train Acc 1.0000, Val Acc 0.7700 (Best 0.7700), Test Acc 0.7580 (Best 0.7571)\n",
      "Loss 0.0185, Train Acc 1.0000, Val Acc 0.7700 (Best 0.7700), Test Acc 0.7580 (Best 0.7571)\n",
      "Loss 0.0172, Train Acc 1.0000, Val Acc 0.7600 (Best 0.7700), Test Acc 0.7571 (Best 0.7571)\n",
      "Loss 0.0160, Train Acc 1.0000, Val Acc 0.7500 (Best 0.7700), Test Acc 0.7563 (Best 0.7571)\n",
      "Loss 0.0150, Train Acc 1.0000, Val Acc 0.7400 (Best 0.7700), Test Acc 0.7554 (Best 0.7571)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "# ~~~~~~~~~~~~~~~~~~\n",
    "# Train and evaluate this network.\n",
    "\n",
    "# Create the model. The output has three logits for three classes.\n",
    "model = HeteroRGCN(G, 10, 10, 3)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    # The loss is computed only for labeled nodes.\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "    val_acc = (pred[val_idx] == labels[val_idx]).float().mean()\n",
    "    test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
