{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCNLayer(nn.Module):\n",
    "#     def __init__(self, in_feats, out_feats):\n",
    "#         super(GCNLayer, self).__init__()\n",
    "#         self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "#     def forward(self, g, feature):\n",
    "#         # Creating a local scope so that all the stored ndata and edata\n",
    "#         # (such as the `'h'` ndata below) are automatically popped out\n",
    "#         # when the scope exits.\n",
    "#         with g.local_scope():\n",
    "#             g.ndata['h'] = feature\n",
    "#             g.update_all(gcn_msg, gcn_reduce)\n",
    "#             h = g.ndata['h']\n",
    "#             return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g = g\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input layer\n",
    "        self.layers.append(GraphConv(in_feats, n_hidden, activation=activation))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(GraphConv(n_hidden, n_hidden, activation=activation))\n",
    "        # output layer\n",
    "        self.layers.append(GraphConv(n_hidden, n_classes))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layer(self.g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.data import register_data_args\n",
    "from dgl.data import CoraGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache failed, re-processing.\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "data = CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "  #Edges 10556\n",
      "  #Classes 7\n",
      "  #Train samples 140\n",
      "  #Val samples 500\n",
      "  #Test samples 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ME\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\data\\utils.py:285: UserWarning: Property dataset.num_labels will be deprecated, please use dataset.num_classes instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "C:\\Users\\ME\\Anaconda3\\envs\\tf-gpu5\\lib\\site-packages\\dgl\\data\\utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset.g instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "in_feats = features.shape[1]\n",
    "n_classes = data.num_labels\n",
    "n_edges = data.graph.number_of_edges()\n",
    "print(\"\"\"----Data statistics------'\n",
    "  #Edges %d\n",
    "  #Classes %d\n",
    "  #Train samples %d\n",
    "  #Val samples %d\n",
    "  #Test samples %d\"\"\" %\n",
    "      (n_edges, n_classes,\n",
    "          train_mask.int().sum().item(),\n",
    "          val_mask.int().sum().item(),\n",
    "          test_mask.int().sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 16\n",
    "n_layers = 1\n",
    "dropout = 0.5\n",
    "weight_decay = 5e-4\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = g.number_of_edges()\n",
    "\n",
    "# normalization\n",
    "degs = g.in_degrees().float()\n",
    "norm = torch.pow(degs, -0.5)\n",
    "norm[torch.isinf(norm)] = 0\n",
    "\n",
    "g.ndata['norm'] = norm.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(g,\n",
    "            in_feats,\n",
    "            n_hidden,\n",
    "            n_classes,\n",
    "            n_layers,\n",
    "            F.relu,\n",
    "            dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weight = model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0478,  0.0296, -0.0427,  ...,  0.0005, -0.0385,  0.0307],\n",
       "        [ 0.0244, -0.0186,  0.0104,  ...,  0.0459, -0.0055, -0.0459],\n",
       "        [ 0.0012, -0.0006, -0.0235,  ...,  0.0482,  0.0159,  0.0404],\n",
       "        ...,\n",
       "        [-0.0318, -0.0606,  0.0195,  ..., -0.0441, -0.0218, -0.0516],\n",
       "        [-0.0455,  0.0088, -0.0339,  ..., -0.0614,  0.0523,  0.0169],\n",
       "        [-0.0205,  0.0078, -0.0483,  ..., -0.0221,  0.0318,  0.0300]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                     lr=lr,\n",
    "                     weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 1.9466 | Accuracy 0.2240 | ETputs(KTEPS) nan\n",
      "Epoch 00001 | Time(s) nan | Loss 1.9411 | Accuracy 0.2380 | ETputs(KTEPS) nan\n",
      "Epoch 00002 | Time(s) nan | Loss 1.9377 | Accuracy 0.2700 | ETputs(KTEPS) nan\n",
      "Epoch 00003 | Time(s) 0.0209 | Loss 1.9301 | Accuracy 0.3980 | ETputs(KTEPS) 504.01\n",
      "Epoch 00004 | Time(s) 0.0219 | Loss 1.9200 | Accuracy 0.5220 | ETputs(KTEPS) 481.07\n",
      "Epoch 00005 | Time(s) 0.0226 | Loss 1.9111 | Accuracy 0.5520 | ETputs(KTEPS) 466.93\n",
      "Epoch 00006 | Time(s) 0.0247 | Loss 1.9044 | Accuracy 0.5460 | ETputs(KTEPS) 427.62\n",
      "Epoch 00007 | Time(s) 0.0249 | Loss 1.8952 | Accuracy 0.5260 | ETputs(KTEPS) 423.32\n",
      "Epoch 00008 | Time(s) 0.0271 | Loss 1.8827 | Accuracy 0.5280 | ETputs(KTEPS) 389.57\n",
      "Epoch 00009 | Time(s) 0.0276 | Loss 1.8704 | Accuracy 0.5160 | ETputs(KTEPS) 381.88\n",
      "Epoch 00010 | Time(s) 0.0281 | Loss 1.8586 | Accuracy 0.5260 | ETputs(KTEPS) 376.32\n",
      "Epoch 00011 | Time(s) 0.0280 | Loss 1.8475 | Accuracy 0.5620 | ETputs(KTEPS) 376.51\n",
      "Epoch 00012 | Time(s) 0.0275 | Loss 1.8327 | Accuracy 0.6000 | ETputs(KTEPS) 383.48\n",
      "Epoch 00013 | Time(s) 0.0276 | Loss 1.8267 | Accuracy 0.6320 | ETputs(KTEPS) 382.98\n",
      "Epoch 00014 | Time(s) 0.0283 | Loss 1.8109 | Accuracy 0.6520 | ETputs(KTEPS) 373.56\n",
      "Epoch 00015 | Time(s) 0.0282 | Loss 1.7897 | Accuracy 0.6660 | ETputs(KTEPS) 373.89\n",
      "Epoch 00016 | Time(s) 0.0278 | Loss 1.7804 | Accuracy 0.6520 | ETputs(KTEPS) 379.94\n",
      "Epoch 00017 | Time(s) 0.0277 | Loss 1.7740 | Accuracy 0.6560 | ETputs(KTEPS) 380.72\n",
      "Epoch 00018 | Time(s) 0.0273 | Loss 1.7447 | Accuracy 0.6480 | ETputs(KTEPS) 386.63\n",
      "Epoch 00019 | Time(s) 0.0274 | Loss 1.7291 | Accuracy 0.6400 | ETputs(KTEPS) 385.29\n",
      "Epoch 00020 | Time(s) 0.0276 | Loss 1.7126 | Accuracy 0.6240 | ETputs(KTEPS) 382.56\n",
      "Epoch 00021 | Time(s) 0.0277 | Loss 1.6926 | Accuracy 0.6160 | ETputs(KTEPS) 381.59\n",
      "Epoch 00022 | Time(s) 0.0287 | Loss 1.6969 | Accuracy 0.6160 | ETputs(KTEPS) 367.50\n",
      "Epoch 00023 | Time(s) 0.0288 | Loss 1.6590 | Accuracy 0.6220 | ETputs(KTEPS) 366.17\n",
      "Epoch 00024 | Time(s) 0.0291 | Loss 1.6491 | Accuracy 0.6420 | ETputs(KTEPS) 362.69\n",
      "Epoch 00025 | Time(s) 0.0288 | Loss 1.6282 | Accuracy 0.6620 | ETputs(KTEPS) 366.62\n",
      "Epoch 00026 | Time(s) 0.0288 | Loss 1.5924 | Accuracy 0.6700 | ETputs(KTEPS) 367.08\n",
      "Epoch 00027 | Time(s) 0.0285 | Loss 1.5872 | Accuracy 0.6800 | ETputs(KTEPS) 370.59\n",
      "Epoch 00028 | Time(s) 0.0283 | Loss 1.5679 | Accuracy 0.6900 | ETputs(KTEPS) 372.38\n",
      "Epoch 00029 | Time(s) 0.0284 | Loss 1.5544 | Accuracy 0.7000 | ETputs(KTEPS) 371.62\n",
      "Epoch 00030 | Time(s) 0.0282 | Loss 1.5309 | Accuracy 0.6960 | ETputs(KTEPS) 374.66\n",
      "Epoch 00031 | Time(s) 0.0280 | Loss 1.4870 | Accuracy 0.6940 | ETputs(KTEPS) 377.54\n",
      "Epoch 00032 | Time(s) 0.0279 | Loss 1.5133 | Accuracy 0.7000 | ETputs(KTEPS) 378.00\n",
      "Epoch 00033 | Time(s) 0.0278 | Loss 1.4844 | Accuracy 0.6980 | ETputs(KTEPS) 380.19\n",
      "Epoch 00034 | Time(s) 0.0278 | Loss 1.4480 | Accuracy 0.6940 | ETputs(KTEPS) 379.27\n",
      "Epoch 00035 | Time(s) 0.0281 | Loss 1.4269 | Accuracy 0.6860 | ETputs(KTEPS) 375.97\n",
      "Epoch 00036 | Time(s) 0.0279 | Loss 1.4239 | Accuracy 0.6800 | ETputs(KTEPS) 378.00\n",
      "Epoch 00037 | Time(s) 0.0279 | Loss 1.3614 | Accuracy 0.6820 | ETputs(KTEPS) 378.78\n",
      "Epoch 00038 | Time(s) 0.0279 | Loss 1.3585 | Accuracy 0.6920 | ETputs(KTEPS) 378.75\n",
      "Epoch 00039 | Time(s) 0.0280 | Loss 1.3430 | Accuracy 0.6940 | ETputs(KTEPS) 377.63\n",
      "Epoch 00040 | Time(s) 0.0278 | Loss 1.3246 | Accuracy 0.6960 | ETputs(KTEPS) 380.14\n",
      "Epoch 00041 | Time(s) 0.0278 | Loss 1.2973 | Accuracy 0.7040 | ETputs(KTEPS) 379.73\n",
      "Epoch 00042 | Time(s) 0.0277 | Loss 1.2892 | Accuracy 0.7100 | ETputs(KTEPS) 381.40\n",
      "Epoch 00043 | Time(s) 0.0276 | Loss 1.2637 | Accuracy 0.7140 | ETputs(KTEPS) 382.33\n",
      "Epoch 00044 | Time(s) 0.0277 | Loss 1.2328 | Accuracy 0.7240 | ETputs(KTEPS) 381.23\n",
      "Epoch 00045 | Time(s) 0.0278 | Loss 1.2167 | Accuracy 0.7280 | ETputs(KTEPS) 380.03\n",
      "Epoch 00046 | Time(s) 0.0276 | Loss 1.2230 | Accuracy 0.7280 | ETputs(KTEPS) 381.85\n",
      "Epoch 00047 | Time(s) 0.0275 | Loss 1.1994 | Accuracy 0.7380 | ETputs(KTEPS) 383.30\n",
      "Epoch 00048 | Time(s) 0.0274 | Loss 1.1802 | Accuracy 0.7360 | ETputs(KTEPS) 385.00\n",
      "Epoch 00049 | Time(s) 0.0274 | Loss 1.1802 | Accuracy 0.7340 | ETputs(KTEPS) 385.15\n",
      "Epoch 00050 | Time(s) 0.0273 | Loss 1.1408 | Accuracy 0.7380 | ETputs(KTEPS) 386.76\n",
      "Epoch 00051 | Time(s) 0.0274 | Loss 1.1144 | Accuracy 0.7380 | ETputs(KTEPS) 385.72\n",
      "Epoch 00052 | Time(s) 0.0274 | Loss 1.1044 | Accuracy 0.7360 | ETputs(KTEPS) 385.84\n",
      "Epoch 00053 | Time(s) 0.0274 | Loss 1.0837 | Accuracy 0.7320 | ETputs(KTEPS) 385.66\n",
      "Epoch 00054 | Time(s) 0.0276 | Loss 1.0663 | Accuracy 0.7320 | ETputs(KTEPS) 382.82\n",
      "Epoch 00055 | Time(s) 0.0276 | Loss 1.0257 | Accuracy 0.7400 | ETputs(KTEPS) 382.06\n",
      "Epoch 00056 | Time(s) 0.0276 | Loss 1.0214 | Accuracy 0.7420 | ETputs(KTEPS) 381.99\n",
      "Epoch 00057 | Time(s) 0.0276 | Loss 1.0152 | Accuracy 0.7480 | ETputs(KTEPS) 382.17\n",
      "Epoch 00058 | Time(s) 0.0277 | Loss 0.9703 | Accuracy 0.7440 | ETputs(KTEPS) 380.86\n",
      "Epoch 00059 | Time(s) 0.0278 | Loss 1.0040 | Accuracy 0.7480 | ETputs(KTEPS) 380.09\n",
      "Epoch 00060 | Time(s) 0.0278 | Loss 0.9260 | Accuracy 0.7520 | ETputs(KTEPS) 379.82\n",
      "Epoch 00061 | Time(s) 0.0277 | Loss 0.9628 | Accuracy 0.7540 | ETputs(KTEPS) 381.18\n",
      "Epoch 00062 | Time(s) 0.0277 | Loss 0.9069 | Accuracy 0.7600 | ETputs(KTEPS) 381.13\n",
      "Epoch 00063 | Time(s) 0.0278 | Loss 0.9307 | Accuracy 0.7660 | ETputs(KTEPS) 379.51\n",
      "Epoch 00064 | Time(s) 0.0279 | Loss 0.8951 | Accuracy 0.7620 | ETputs(KTEPS) 378.61\n",
      "Epoch 00065 | Time(s) 0.0278 | Loss 0.9300 | Accuracy 0.7620 | ETputs(KTEPS) 379.24\n",
      "Epoch 00066 | Time(s) 0.0278 | Loss 0.8839 | Accuracy 0.7580 | ETputs(KTEPS) 379.22\n",
      "Epoch 00067 | Time(s) 0.0277 | Loss 0.8747 | Accuracy 0.7560 | ETputs(KTEPS) 380.45\n",
      "Epoch 00068 | Time(s) 0.0278 | Loss 0.8605 | Accuracy 0.7560 | ETputs(KTEPS) 379.76\n",
      "Epoch 00069 | Time(s) 0.0279 | Loss 0.8479 | Accuracy 0.7580 | ETputs(KTEPS) 378.89\n",
      "Epoch 00070 | Time(s) 0.0278 | Loss 0.8180 | Accuracy 0.7560 | ETputs(KTEPS) 379.28\n",
      "Epoch 00071 | Time(s) 0.0278 | Loss 0.8641 | Accuracy 0.7540 | ETputs(KTEPS) 379.45\n",
      "Epoch 00072 | Time(s) 0.0277 | Loss 0.8299 | Accuracy 0.7520 | ETputs(KTEPS) 380.59\n",
      "Epoch 00073 | Time(s) 0.0278 | Loss 0.7997 | Accuracy 0.7520 | ETputs(KTEPS) 380.35\n",
      "Epoch 00074 | Time(s) 0.0277 | Loss 0.7393 | Accuracy 0.7540 | ETputs(KTEPS) 381.08\n",
      "Epoch 00075 | Time(s) 0.0277 | Loss 0.7565 | Accuracy 0.7540 | ETputs(KTEPS) 381.22\n",
      "Epoch 00076 | Time(s) 0.0276 | Loss 0.7579 | Accuracy 0.7620 | ETputs(KTEPS) 382.65\n",
      "Epoch 00077 | Time(s) 0.0276 | Loss 0.7302 | Accuracy 0.7580 | ETputs(KTEPS) 382.92\n",
      "Epoch 00078 | Time(s) 0.0275 | Loss 0.7536 | Accuracy 0.7560 | ETputs(KTEPS) 383.96\n",
      "Epoch 00079 | Time(s) 0.0275 | Loss 0.7694 | Accuracy 0.7580 | ETputs(KTEPS) 383.52\n",
      "Epoch 00080 | Time(s) 0.0276 | Loss 0.7247 | Accuracy 0.7580 | ETputs(KTEPS) 382.56\n",
      "Epoch 00081 | Time(s) 0.0276 | Loss 0.7099 | Accuracy 0.7600 | ETputs(KTEPS) 382.84\n",
      "Epoch 00082 | Time(s) 0.0275 | Loss 0.6989 | Accuracy 0.7680 | ETputs(KTEPS) 384.00\n",
      "Epoch 00083 | Time(s) 0.0275 | Loss 0.7038 | Accuracy 0.7680 | ETputs(KTEPS) 384.06\n",
      "Epoch 00084 | Time(s) 0.0274 | Loss 0.6605 | Accuracy 0.7720 | ETputs(KTEPS) 384.99\n",
      "Epoch 00085 | Time(s) 0.0275 | Loss 0.6714 | Accuracy 0.7700 | ETputs(KTEPS) 384.05\n",
      "Epoch 00086 | Time(s) 0.0275 | Loss 0.6820 | Accuracy 0.7680 | ETputs(KTEPS) 384.13\n",
      "Epoch 00087 | Time(s) 0.0275 | Loss 0.7305 | Accuracy 0.7660 | ETputs(KTEPS) 383.38\n",
      "Epoch 00088 | Time(s) 0.0275 | Loss 0.7022 | Accuracy 0.7700 | ETputs(KTEPS) 384.11\n",
      "Epoch 00089 | Time(s) 0.0274 | Loss 0.6614 | Accuracy 0.7760 | ETputs(KTEPS) 384.68\n",
      "Epoch 00090 | Time(s) 0.0275 | Loss 0.6448 | Accuracy 0.7680 | ETputs(KTEPS) 384.28\n",
      "Epoch 00091 | Time(s) 0.0276 | Loss 0.6945 | Accuracy 0.7680 | ETputs(KTEPS) 383.03\n",
      "Epoch 00092 | Time(s) 0.0275 | Loss 0.6609 | Accuracy 0.7720 | ETputs(KTEPS) 383.59\n",
      "Epoch 00093 | Time(s) 0.0275 | Loss 0.6365 | Accuracy 0.7700 | ETputs(KTEPS) 384.29\n",
      "Epoch 00094 | Time(s) 0.0274 | Loss 0.6321 | Accuracy 0.7680 | ETputs(KTEPS) 384.98\n",
      "Epoch 00095 | Time(s) 0.0275 | Loss 0.6518 | Accuracy 0.7660 | ETputs(KTEPS) 384.45\n",
      "Epoch 00096 | Time(s) 0.0275 | Loss 0.6336 | Accuracy 0.7680 | ETputs(KTEPS) 384.38\n",
      "Epoch 00097 | Time(s) 0.0274 | Loss 0.6140 | Accuracy 0.7640 | ETputs(KTEPS) 385.20\n",
      "Epoch 00098 | Time(s) 0.0274 | Loss 0.5856 | Accuracy 0.7640 | ETputs(KTEPS) 384.98\n",
      "Epoch 00099 | Time(s) 0.0274 | Loss 0.6177 | Accuracy 0.7680 | ETputs(KTEPS) 385.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00100 | Time(s) 0.0274 | Loss 0.6142 | Accuracy 0.7700 | ETputs(KTEPS) 385.40\n",
      "Epoch 00101 | Time(s) 0.0274 | Loss 0.5575 | Accuracy 0.7760 | ETputs(KTEPS) 384.62\n",
      "Epoch 00102 | Time(s) 0.0275 | Loss 0.5527 | Accuracy 0.7780 | ETputs(KTEPS) 384.14\n",
      "Epoch 00103 | Time(s) 0.0274 | Loss 0.6021 | Accuracy 0.7780 | ETputs(KTEPS) 384.90\n",
      "Epoch 00104 | Time(s) 0.0274 | Loss 0.5804 | Accuracy 0.7760 | ETputs(KTEPS) 385.52\n",
      "Epoch 00105 | Time(s) 0.0274 | Loss 0.5897 | Accuracy 0.7680 | ETputs(KTEPS) 384.63\n",
      "Epoch 00106 | Time(s) 0.0275 | Loss 0.5767 | Accuracy 0.7680 | ETputs(KTEPS) 383.63\n",
      "Epoch 00107 | Time(s) 0.0275 | Loss 0.5559 | Accuracy 0.7700 | ETputs(KTEPS) 383.64\n",
      "Epoch 00108 | Time(s) 0.0275 | Loss 0.5903 | Accuracy 0.7660 | ETputs(KTEPS) 384.11\n",
      "Epoch 00109 | Time(s) 0.0275 | Loss 0.5577 | Accuracy 0.7700 | ETputs(KTEPS) 384.05\n",
      "Epoch 00110 | Time(s) 0.0275 | Loss 0.5837 | Accuracy 0.7680 | ETputs(KTEPS) 383.35\n",
      "Epoch 00111 | Time(s) 0.0275 | Loss 0.5762 | Accuracy 0.7680 | ETputs(KTEPS) 383.56\n",
      "Epoch 00112 | Time(s) 0.0276 | Loss 0.5991 | Accuracy 0.7620 | ETputs(KTEPS) 383.12\n",
      "Epoch 00113 | Time(s) 0.0275 | Loss 0.5327 | Accuracy 0.7660 | ETputs(KTEPS) 383.58\n",
      "Epoch 00114 | Time(s) 0.0275 | Loss 0.5392 | Accuracy 0.7680 | ETputs(KTEPS) 384.27\n",
      "Epoch 00115 | Time(s) 0.0275 | Loss 0.5526 | Accuracy 0.7640 | ETputs(KTEPS) 383.72\n",
      "Epoch 00116 | Time(s) 0.0275 | Loss 0.5515 | Accuracy 0.7620 | ETputs(KTEPS) 383.31\n",
      "Epoch 00117 | Time(s) 0.0276 | Loss 0.5473 | Accuracy 0.7580 | ETputs(KTEPS) 383.14\n",
      "Epoch 00118 | Time(s) 0.0276 | Loss 0.5534 | Accuracy 0.7600 | ETputs(KTEPS) 382.98\n",
      "Epoch 00119 | Time(s) 0.0275 | Loss 0.5076 | Accuracy 0.7660 | ETputs(KTEPS) 383.41\n",
      "Epoch 00120 | Time(s) 0.0276 | Loss 0.5327 | Accuracy 0.7680 | ETputs(KTEPS) 382.99\n",
      "Epoch 00121 | Time(s) 0.0277 | Loss 0.5110 | Accuracy 0.7720 | ETputs(KTEPS) 381.19\n",
      "Epoch 00122 | Time(s) 0.0277 | Loss 0.5020 | Accuracy 0.7760 | ETputs(KTEPS) 380.48\n",
      "Epoch 00123 | Time(s) 0.0279 | Loss 0.4775 | Accuracy 0.7780 | ETputs(KTEPS) 378.42\n",
      "Epoch 00124 | Time(s) 0.0280 | Loss 0.5464 | Accuracy 0.7780 | ETputs(KTEPS) 376.98\n",
      "Epoch 00125 | Time(s) 0.0280 | Loss 0.5406 | Accuracy 0.7780 | ETputs(KTEPS) 376.33\n",
      "Epoch 00126 | Time(s) 0.0281 | Loss 0.5085 | Accuracy 0.7780 | ETputs(KTEPS) 376.02\n",
      "Epoch 00127 | Time(s) 0.0281 | Loss 0.4707 | Accuracy 0.7780 | ETputs(KTEPS) 376.04\n",
      "Epoch 00128 | Time(s) 0.0281 | Loss 0.4816 | Accuracy 0.7800 | ETputs(KTEPS) 375.20\n",
      "Epoch 00129 | Time(s) 0.0292 | Loss 0.5222 | Accuracy 0.7780 | ETputs(KTEPS) 360.95\n",
      "Epoch 00130 | Time(s) 0.0293 | Loss 0.4886 | Accuracy 0.7780 | ETputs(KTEPS) 360.57\n",
      "Epoch 00131 | Time(s) 0.0293 | Loss 0.4875 | Accuracy 0.7740 | ETputs(KTEPS) 360.51\n",
      "Epoch 00132 | Time(s) 0.0293 | Loss 0.4821 | Accuracy 0.7740 | ETputs(KTEPS) 360.35\n",
      "Epoch 00133 | Time(s) 0.0293 | Loss 0.4686 | Accuracy 0.7680 | ETputs(KTEPS) 359.92\n",
      "Epoch 00134 | Time(s) 0.0293 | Loss 0.4619 | Accuracy 0.7680 | ETputs(KTEPS) 359.96\n",
      "Epoch 00135 | Time(s) 0.0296 | Loss 0.4987 | Accuracy 0.7680 | ETputs(KTEPS) 356.29\n",
      "Epoch 00136 | Time(s) 0.0299 | Loss 0.5075 | Accuracy 0.7720 | ETputs(KTEPS) 352.71\n",
      "Epoch 00137 | Time(s) 0.0300 | Loss 0.4741 | Accuracy 0.7780 | ETputs(KTEPS) 352.19\n",
      "Epoch 00138 | Time(s) 0.0299 | Loss 0.5252 | Accuracy 0.7820 | ETputs(KTEPS) 352.54\n",
      "Epoch 00139 | Time(s) 0.0299 | Loss 0.5012 | Accuracy 0.7800 | ETputs(KTEPS) 352.89\n",
      "Epoch 00140 | Time(s) 0.0299 | Loss 0.4735 | Accuracy 0.7800 | ETputs(KTEPS) 353.48\n",
      "Epoch 00141 | Time(s) 0.0299 | Loss 0.4779 | Accuracy 0.7840 | ETputs(KTEPS) 353.40\n",
      "Epoch 00142 | Time(s) 0.0299 | Loss 0.4687 | Accuracy 0.7820 | ETputs(KTEPS) 352.89\n",
      "Epoch 00143 | Time(s) 0.0299 | Loss 0.4710 | Accuracy 0.7820 | ETputs(KTEPS) 353.05\n",
      "Epoch 00144 | Time(s) 0.0299 | Loss 0.4182 | Accuracy 0.7780 | ETputs(KTEPS) 352.97\n",
      "Epoch 00145 | Time(s) 0.0310 | Loss 0.4853 | Accuracy 0.7780 | ETputs(KTEPS) 340.49\n",
      "Epoch 00146 | Time(s) 0.0310 | Loss 0.4512 | Accuracy 0.7780 | ETputs(KTEPS) 340.26\n",
      "Epoch 00147 | Time(s) 0.0310 | Loss 0.4215 | Accuracy 0.7780 | ETputs(KTEPS) 340.19\n",
      "Epoch 00148 | Time(s) 0.0310 | Loss 0.4681 | Accuracy 0.7780 | ETputs(KTEPS) 340.57\n",
      "Epoch 00149 | Time(s) 0.0310 | Loss 0.4345 | Accuracy 0.7800 | ETputs(KTEPS) 340.79\n",
      "Epoch 00150 | Time(s) 0.0310 | Loss 0.4708 | Accuracy 0.7780 | ETputs(KTEPS) 340.43\n",
      "Epoch 00151 | Time(s) 0.0310 | Loss 0.4260 | Accuracy 0.7780 | ETputs(KTEPS) 340.80\n",
      "Epoch 00152 | Time(s) 0.0309 | Loss 0.4497 | Accuracy 0.7760 | ETputs(KTEPS) 341.32\n",
      "Epoch 00153 | Time(s) 0.0309 | Loss 0.5144 | Accuracy 0.7800 | ETputs(KTEPS) 341.39\n",
      "Epoch 00154 | Time(s) 0.0309 | Loss 0.4429 | Accuracy 0.7820 | ETputs(KTEPS) 341.61\n",
      "Epoch 00155 | Time(s) 0.0309 | Loss 0.4377 | Accuracy 0.7800 | ETputs(KTEPS) 341.47\n",
      "Epoch 00156 | Time(s) 0.0309 | Loss 0.3937 | Accuracy 0.7820 | ETputs(KTEPS) 341.39\n",
      "Epoch 00157 | Time(s) 0.0309 | Loss 0.4701 | Accuracy 0.7820 | ETputs(KTEPS) 341.67\n",
      "Epoch 00158 | Time(s) 0.0308 | Loss 0.4143 | Accuracy 0.7820 | ETputs(KTEPS) 342.23\n",
      "Epoch 00159 | Time(s) 0.0309 | Loss 0.4051 | Accuracy 0.7840 | ETputs(KTEPS) 341.86\n",
      "Epoch 00160 | Time(s) 0.0309 | Loss 0.4152 | Accuracy 0.7880 | ETputs(KTEPS) 342.13\n",
      "Epoch 00161 | Time(s) 0.0308 | Loss 0.4041 | Accuracy 0.7820 | ETputs(KTEPS) 342.75\n",
      "Epoch 00162 | Time(s) 0.0308 | Loss 0.3948 | Accuracy 0.7800 | ETputs(KTEPS) 343.16\n",
      "Epoch 00163 | Time(s) 0.0307 | Loss 0.4336 | Accuracy 0.7800 | ETputs(KTEPS) 343.43\n",
      "Epoch 00164 | Time(s) 0.0307 | Loss 0.4138 | Accuracy 0.7800 | ETputs(KTEPS) 343.62\n",
      "Epoch 00165 | Time(s) 0.0307 | Loss 0.4496 | Accuracy 0.7760 | ETputs(KTEPS) 344.02\n",
      "Epoch 00166 | Time(s) 0.0306 | Loss 0.4474 | Accuracy 0.7740 | ETputs(KTEPS) 344.55\n",
      "Epoch 00167 | Time(s) 0.0306 | Loss 0.3833 | Accuracy 0.7800 | ETputs(KTEPS) 345.14\n",
      "Epoch 00168 | Time(s) 0.0305 | Loss 0.3860 | Accuracy 0.7860 | ETputs(KTEPS) 345.66\n",
      "Epoch 00169 | Time(s) 0.0305 | Loss 0.4492 | Accuracy 0.7900 | ETputs(KTEPS) 346.25\n",
      "Epoch 00170 | Time(s) 0.0304 | Loss 0.3749 | Accuracy 0.7900 | ETputs(KTEPS) 346.69\n",
      "Epoch 00171 | Time(s) 0.0304 | Loss 0.3784 | Accuracy 0.7880 | ETputs(KTEPS) 346.99\n",
      "Epoch 00172 | Time(s) 0.0304 | Loss 0.4270 | Accuracy 0.7900 | ETputs(KTEPS) 347.02\n",
      "Epoch 00173 | Time(s) 0.0304 | Loss 0.4074 | Accuracy 0.7900 | ETputs(KTEPS) 347.58\n",
      "Epoch 00174 | Time(s) 0.0303 | Loss 0.4101 | Accuracy 0.7820 | ETputs(KTEPS) 348.27\n",
      "Epoch 00175 | Time(s) 0.0303 | Loss 0.3814 | Accuracy 0.7820 | ETputs(KTEPS) 348.96\n",
      "Epoch 00176 | Time(s) 0.0302 | Loss 0.4324 | Accuracy 0.7820 | ETputs(KTEPS) 349.30\n",
      "Epoch 00177 | Time(s) 0.0302 | Loss 0.4003 | Accuracy 0.7800 | ETputs(KTEPS) 349.78\n",
      "Epoch 00178 | Time(s) 0.0301 | Loss 0.4271 | Accuracy 0.7780 | ETputs(KTEPS) 350.19\n",
      "Epoch 00179 | Time(s) 0.0301 | Loss 0.4236 | Accuracy 0.7820 | ETputs(KTEPS) 350.65\n",
      "Epoch 00180 | Time(s) 0.0301 | Loss 0.3884 | Accuracy 0.7900 | ETputs(KTEPS) 351.06\n",
      "Epoch 00181 | Time(s) 0.0301 | Loss 0.4247 | Accuracy 0.7900 | ETputs(KTEPS) 351.25\n",
      "Epoch 00182 | Time(s) 0.0302 | Loss 0.4267 | Accuracy 0.7920 | ETputs(KTEPS) 350.09\n",
      "Epoch 00183 | Time(s) 0.0301 | Loss 0.4164 | Accuracy 0.7920 | ETputs(KTEPS) 350.36\n",
      "Epoch 00184 | Time(s) 0.0301 | Loss 0.4151 | Accuracy 0.7900 | ETputs(KTEPS) 350.44\n",
      "Epoch 00185 | Time(s) 0.0301 | Loss 0.3817 | Accuracy 0.7860 | ETputs(KTEPS) 350.51\n",
      "Epoch 00186 | Time(s) 0.0301 | Loss 0.3679 | Accuracy 0.7800 | ETputs(KTEPS) 350.39\n",
      "Epoch 00187 | Time(s) 0.0301 | Loss 0.3685 | Accuracy 0.7800 | ETputs(KTEPS) 350.84\n",
      "Epoch 00188 | Time(s) 0.0301 | Loss 0.4362 | Accuracy 0.7760 | ETputs(KTEPS) 351.22\n",
      "Epoch 00189 | Time(s) 0.0300 | Loss 0.4089 | Accuracy 0.7760 | ETputs(KTEPS) 351.35\n",
      "Epoch 00190 | Time(s) 0.0301 | Loss 0.3715 | Accuracy 0.7760 | ETputs(KTEPS) 351.23\n",
      "Epoch 00191 | Time(s) 0.0300 | Loss 0.4409 | Accuracy 0.7740 | ETputs(KTEPS) 351.61\n",
      "Epoch 00192 | Time(s) 0.0300 | Loss 0.3840 | Accuracy 0.7840 | ETputs(KTEPS) 351.74\n",
      "Epoch 00193 | Time(s) 0.0300 | Loss 0.3817 | Accuracy 0.7840 | ETputs(KTEPS) 352.29\n",
      "Epoch 00194 | Time(s) 0.0299 | Loss 0.4058 | Accuracy 0.7880 | ETputs(KTEPS) 352.78\n",
      "Epoch 00195 | Time(s) 0.0299 | Loss 0.3992 | Accuracy 0.7900 | ETputs(KTEPS) 352.48\n",
      "Epoch 00196 | Time(s) 0.0299 | Loss 0.3604 | Accuracy 0.7880 | ETputs(KTEPS) 352.85\n",
      "Epoch 00197 | Time(s) 0.0299 | Loss 0.4092 | Accuracy 0.7900 | ETputs(KTEPS) 353.21\n",
      "Epoch 00198 | Time(s) 0.0299 | Loss 0.3467 | Accuracy 0.7880 | ETputs(KTEPS) 353.21\n",
      "Epoch 00199 | Time(s) 0.0299 | Loss 0.4298 | Accuracy 0.7880 | ETputs(KTEPS) 353.62\n"
     ]
    }
   ],
   "source": [
    "dur = []\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    # forward\n",
    "    logits = model(features)\n",
    "    loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    acc = evaluate(model, features, labels, val_mask)\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | Accuracy {:.4f} | \"\n",
    "          \"ETputs(KTEPS) {:.2f}\". format(epoch, np.mean(dur), loss.item(),\n",
    "                                         acc, n_edges / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy 80.10%\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "acc = evaluate(model, features, labels, test_mask)\n",
    "print(\"Test accuracy {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activation',\n",
       " '_allow_zero_in_degree',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_unimplemented',\n",
       " '_get_name',\n",
       " '_in_feats',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm',\n",
       " '_out_feats',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_allow_zero_in_degree',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weight = model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 6.8080e-02, -1.6991e-02, -9.5129e-03,  ..., -4.8230e-03,\n",
       "          2.2167e-03,  8.0389e-07],\n",
       "        [ 1.2927e-01, -1.0263e-01, -3.5900e-01,  ..., -2.6162e-01,\n",
       "         -9.1564e-02, -6.6161e-07],\n",
       "        [ 6.9595e-03, -4.3922e-01, -1.8890e-01,  ..., -1.9583e-01,\n",
       "         -1.0577e-01, -3.5050e-07],\n",
       "        ...,\n",
       "        [-7.6585e-03, -7.9028e-02, -5.4745e-03,  ..., -1.8528e-02,\n",
       "          2.9665e-02, -3.7492e-07],\n",
       "        [-1.2457e-02,  7.9623e-02,  1.0097e-01,  ...,  6.0082e-02,\n",
       "          1.3345e-01, -8.2251e-07],\n",
       "        [-6.7522e-02,  1.9789e-01,  9.2289e-02,  ...,  1.4291e-01,\n",
       "          1.1179e-02, -2.5974e-07]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
