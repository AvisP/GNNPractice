{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/MUTAG.zip\n",
      "Extracting data\\TUDataset\\MUTAG\\MUTAG.zip\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(edge_attr=[38, 4], edge_index=[2, 38], x=[17, 7], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 150\n",
      "Number of test graphs: 38\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[1169], edge_attr=[2592, 4], edge_index=[2, 2592], x=[1169, 7], y=[64])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[1116], edge_attr=[2444, 4], edge_index=[2, 2444], x=[1116, 7], y=[64])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 22\n",
      "Batch(batch=[429], edge_attr=[958, 4], edge_index=[2, 958], x=[429, 7], y=[22])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(7, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "    return loss\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6066, Train Acc: 0.8333, Test Acc: 0.7368\n",
      "Epoch: 002, Loss: 0.5612, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 003, Loss: 0.4483, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 004, Loss: 0.4561, Train Acc: 0.8133, Test Acc: 0.7105\n",
      "Epoch: 005, Loss: 0.5360, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 006, Loss: 0.3752, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 007, Loss: 0.8071, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 008, Loss: 0.3983, Train Acc: 0.7867, Test Acc: 0.7895\n",
      "Epoch: 009, Loss: 0.3071, Train Acc: 0.8267, Test Acc: 0.7105\n",
      "Epoch: 010, Loss: 0.3858, Train Acc: 0.8267, Test Acc: 0.7105\n",
      "Epoch: 011, Loss: 0.2929, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 012, Loss: 0.2235, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 013, Loss: 0.5332, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 014, Loss: 0.4019, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 015, Loss: 0.3074, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 016, Loss: 0.4656, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 017, Loss: 0.3468, Train Acc: 0.8333, Test Acc: 0.7368\n",
      "Epoch: 018, Loss: 0.5346, Train Acc: 0.8333, Test Acc: 0.7368\n",
      "Epoch: 019, Loss: 0.5325, Train Acc: 0.8200, Test Acc: 0.7105\n",
      "Epoch: 020, Loss: 0.6082, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 021, Loss: 0.1961, Train Acc: 0.8133, Test Acc: 0.7368\n",
      "Epoch: 022, Loss: 0.1635, Train Acc: 0.8000, Test Acc: 0.7632\n",
      "Epoch: 023, Loss: 0.2583, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 024, Loss: 0.3593, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 025, Loss: 0.4697, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 026, Loss: 0.6221, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 027, Loss: 0.5680, Train Acc: 0.8200, Test Acc: 0.6842\n",
      "Epoch: 028, Loss: 0.3246, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 029, Loss: 0.4662, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 030, Loss: 0.3180, Train Acc: 0.8600, Test Acc: 0.6579\n",
      "Epoch: 031, Loss: 0.2749, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 032, Loss: 0.3200, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 033, Loss: 0.6072, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 034, Loss: 0.6330, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 035, Loss: 0.3108, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 036, Loss: 0.3775, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 037, Loss: 0.3127, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 038, Loss: 0.3326, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 039, Loss: 0.4753, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 040, Loss: 0.3633, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 041, Loss: 0.5000, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 042, Loss: 0.3979, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 043, Loss: 0.3557, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 044, Loss: 0.9543, Train Acc: 0.8200, Test Acc: 0.6842\n",
      "Epoch: 045, Loss: 0.4330, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 046, Loss: 0.4143, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 047, Loss: 0.4503, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 048, Loss: 0.4334, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 049, Loss: 0.4820, Train Acc: 0.8000, Test Acc: 0.7105\n",
      "Epoch: 050, Loss: 0.3709, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 051, Loss: 0.5128, Train Acc: 0.7933, Test Acc: 0.7895\n",
      "Epoch: 052, Loss: 0.6858, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 053, Loss: 0.5482, Train Acc: 0.8067, Test Acc: 0.6842\n",
      "Epoch: 054, Loss: 0.3697, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 055, Loss: 0.5015, Train Acc: 0.8533, Test Acc: 0.7368\n",
      "Epoch: 056, Loss: 0.4861, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 057, Loss: 0.4424, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 058, Loss: 0.5734, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 059, Loss: 0.3141, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 060, Loss: 0.3765, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 061, Loss: 0.3558, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 062, Loss: 0.4136, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 063, Loss: 0.3522, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 064, Loss: 0.4016, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 065, Loss: 0.3413, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 066, Loss: 0.5650, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 067, Loss: 0.4401, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 068, Loss: 0.4622, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 069, Loss: 0.2730, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 070, Loss: 0.6866, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 071, Loss: 0.3828, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 072, Loss: 0.3366, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 073, Loss: 0.5296, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 074, Loss: 0.4653, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 075, Loss: 0.4540, Train Acc: 0.8467, Test Acc: 0.7632\n",
      "Epoch: 076, Loss: 0.4250, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 077, Loss: 0.4071, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 078, Loss: 0.5867, Train Acc: 0.8200, Test Acc: 0.6842\n",
      "Epoch: 079, Loss: 0.2898, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 080, Loss: 0.3028, Train Acc: 0.8267, Test Acc: 0.7105\n",
      "Epoch: 081, Loss: 0.4643, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 082, Loss: 0.6072, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 083, Loss: 0.4783, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 084, Loss: 0.2751, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 085, Loss: 0.4249, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 086, Loss: 0.2611, Train Acc: 0.8467, Test Acc: 0.7368\n",
      "Epoch: 087, Loss: 0.4872, Train Acc: 0.8600, Test Acc: 0.6579\n",
      "Epoch: 088, Loss: 0.4217, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 089, Loss: 0.2588, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 090, Loss: 0.1852, Train Acc: 0.8467, Test Acc: 0.7368\n",
      "Epoch: 091, Loss: 0.2946, Train Acc: 0.8533, Test Acc: 0.7368\n",
      "Epoch: 092, Loss: 0.3575, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 093, Loss: 0.6492, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 094, Loss: 0.3595, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 095, Loss: 0.4046, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 096, Loss: 0.4387, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 097, Loss: 0.5745, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 098, Loss: 0.3971, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 099, Loss: 0.4462, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 100, Loss: 0.3845, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 101, Loss: 0.4368, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 102, Loss: 0.6178, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 103, Loss: 0.5087, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 104, Loss: 0.5053, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 105, Loss: 0.4371, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 106, Loss: 0.4798, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 107, Loss: 0.3370, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 108, Loss: 0.4797, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 109, Loss: 0.2254, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 110, Loss: 0.3647, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 111, Loss: 0.3464, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 112, Loss: 0.4997, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 113, Loss: 0.5547, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 114, Loss: 0.3022, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 115, Loss: 0.7019, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 116, Loss: 0.3286, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 117, Loss: 0.5815, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 118, Loss: 0.3745, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 119, Loss: 0.2563, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 120, Loss: 0.3984, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 121, Loss: 0.7692, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 122, Loss: 0.3763, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 123, Loss: 0.3879, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 124, Loss: 0.3228, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 125, Loss: 0.3687, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 126, Loss: 0.2906, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 127, Loss: 0.3577, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 128, Loss: 0.8427, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 129, Loss: 0.4388, Train Acc: 0.8400, Test Acc: 0.6316\n",
      "Epoch: 130, Loss: 0.3858, Train Acc: 0.8333, Test Acc: 0.6316\n",
      "Epoch: 131, Loss: 0.6503, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 132, Loss: 0.4163, Train Acc: 0.8533, Test Acc: 0.7368\n",
      "Epoch: 133, Loss: 0.5578, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 134, Loss: 0.2675, Train Acc: 0.8267, Test Acc: 0.6579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Loss: 0.3513, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 136, Loss: 0.4068, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 137, Loss: 0.4427, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 138, Loss: 0.4316, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 139, Loss: 0.3445, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 140, Loss: 0.5308, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 141, Loss: 0.5235, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 142, Loss: 0.2773, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 143, Loss: 0.4170, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 144, Loss: 0.3675, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 145, Loss: 0.3138, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 146, Loss: 0.2580, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 147, Loss: 0.3348, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 148, Loss: 0.5727, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 149, Loss: 0.2897, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 150, Loss: 0.2982, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 151, Loss: 0.4342, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 152, Loss: 0.3814, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 153, Loss: 0.3965, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 154, Loss: 0.6643, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 155, Loss: 0.2692, Train Acc: 0.8333, Test Acc: 0.7105\n",
      "Epoch: 156, Loss: 0.3319, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 157, Loss: 0.2665, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 158, Loss: 0.2404, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 159, Loss: 0.2974, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 160, Loss: 0.2075, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 161, Loss: 0.3953, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 162, Loss: 0.2673, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 163, Loss: 0.2312, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 164, Loss: 0.3162, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 165, Loss: 0.3270, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 166, Loss: 0.2341, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 167, Loss: 0.4171, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 168, Loss: 0.2781, Train Acc: 0.8267, Test Acc: 0.6842\n",
      "Epoch: 169, Loss: 0.1900, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 170, Loss: 0.2423, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 171, Loss: 0.4753, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 172, Loss: 0.3695, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 173, Loss: 0.3043, Train Acc: 0.8533, Test Acc: 0.6579\n",
      "Epoch: 174, Loss: 0.3731, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 175, Loss: 0.4601, Train Acc: 0.8533, Test Acc: 0.7105\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "\n",
    "for epoch in range(1, 176):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[2714], edge_attr=[5994, 4], edge_index=[2, 5994], x=[2714, 7], y=[150])\n"
     ]
    }
   ],
   "source": [
    "final_loader = DataLoader(train_dataset, batch_size=150, shuffle=True)\n",
    "for data in final_loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.conv1(data.x, data.edge_index)\n",
    "x = x.relu()\n",
    "x = model.conv2(x, data.edge_index)\n",
    "x = x.relu()\n",
    "x = model.conv3(x, data.edge_index)\n",
    "\n",
    "# 2. Readout layer\n",
    "x = global_mean_pool(x, data.batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0104,  0.0261,  0.1254,  ...,  0.0156, -0.1207, -0.0571],\n",
       "        [-0.0156, -0.0010,  0.1657,  ...,  0.0374, -0.1363, -0.0853],\n",
       "        [ 0.0260,  0.0326,  0.1150,  ...,  0.0135, -0.1281, -0.0523],\n",
       "        ...,\n",
       "        [-0.2665,  0.1849, -0.0837,  ..., -0.1741,  0.1978,  0.2073],\n",
       "        [ 0.6496, -0.5655,  0.8123,  ...,  0.2333, -0.7444, -0.3861],\n",
       "        [-0.0757,  0.0856,  0.0484,  ..., -0.0336, -0.0009,  0.0312]],\n",
       "       grad_fn=<TrueDivideBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.conv1(train_loader.dataset.data.x, train_loader.dataset.data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel('TSNE Component 1')\n",
    "    plt.ylabel('TSNE Component 2')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=50, c=color, cmap=\"Set2\")\n",
    "#     plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAI8CAYAAAAOWIRFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXRc2X0f+O99r/bCvhd2EBt3stng3i1KbEndkqKlbck6SiLJHnkyE8/RsS1nFNmJJ3ZmpCiWjzLjnBPHimUnSiIlTiRZe7da1tbN5gbuJMAF+74DBVShllfv3fkDSwNEvUKBrFeFAr6fPjgE6lY9/MAmgS/vve93hZQSRERERLSRkukCiIiIiLYrBiUiIiIiEwxKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjJhs+KiJSUlsr6+3opLExEREaXUtWvXpqSUpfHGLAlK9fX1aG9vt+LSRERERCklhOg3G+PSGxEREZEJBiUiIiIiEwxKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjLBoERERERkgkGJiIiIyASDEhEREZEJBiUiIiIiEwxKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjLBoERERERkgkGJiIiIyASDEhEREZEJBiUiIiIiEwxKRERERCZsmS5gq+YW5vHLO9ex6J9HRBhYyHPgba2Hcbi4OtOlERER0Q6TVUFpYnoKFy9dgpASOVCQAwX5Mzqutrdj+mAQZyoa4VBUCCEyXSoRERHtAFkTlKSUaG9vhyoB4K0gZINAsabiF/dv4b/1XINHteNwcRXeWbUPNTmFGauXiIiIsl/WBCW/349YLBZ3U5UNAvVRB0YdMSzqGi5N9OHyRB8ac0vx6YNvh8tmT3u9RERElP2yZjO3pmmQCcYdcv1ymwTQtTCJv7x/wfQ1/mgIk6EFGNJITZFERES0o2TNjFJeXh5UCCBOXDIgMW2LxX3d3dkRzEYWUej0rD42EJjB1x5exuiiH4oQsCsqPlh/BOd8zVaVT0RERFkoa2aUnE4nKnwV0OMGJaDHGY37OglgPDS/+vFEaAF/eusnGAzOIiYNRA0dwVgU/7PnOn4+8tCi6omIiCgbZU1QAoBnjhxFhc8HCUCDRAwSIWHgsncRi4r5wly+w736/g8H7iJqbJx9iho6vtN3C7rBZTgiIiJakjVLbwCgqipOPtuGSCSCqdkZ/GC4A9eC42tvgtv4GiHg8+SvftwxN2q610mHxFhoHlXegtQWTkRERFkpq4LSCqfTiaoKH/5+cSH6bryKmUjQNPy8t+bguo9tQjW9rpQSdsV8PB3GFudxZaIPwVgULfllOFpcDVXJqok/IiKiHSMrg9KKHLsLf/Ts+3Blsg/f7b+D+WhoNTApQuD58ia8r3Z9UDpV3oBXBzsQi3OnW77DjVJXThoqj+87fbfw2vB96IYBAxIXJ3rwzV4nPnvkXShYsxmdiIiI0iOrgxIAOFQbnqtownMVTZgMLeDu7CgUIXCoqBJFTu+G57+zai8uT/RiLhJaDUsCgF1R8Ynmkxnr6t0xO4qfDN+HZuirj0X0GDRdx1fuX8Bnj7wrI3URERHtZlkflNYqdefiHe7chM/x2Bz4g6PvwY+HOnBxvAea1NGcX4731x7KaCfv14Y6EV0TklYYkBgIzGAqHEBJBme7iIiIdqMdFZSS5bU78HLDUbzccDTTpayaDAdMx2xCwUw4yKBERESUZtwlvE1UePJMx2LSQOkmM2VERESUertyRslqmqHj2uQArkz2AQBOlNbj2dLahHfUvVi9Hw/mxjcsv6lCQXNe6brO4kRERJQeDEopMh8N483xbvQvzOChfwJRI7Yaerr8k3h1qAOfPfJuuE0O6G3OL8OH6o/gW703IbA0i+RQbCh15+BTe8+m8SshIiKiFQxKKdA5O4Z/1/FLSCmhyY0bsiNGDBOhBXy77yb+ftNx0+u8ULUXbaV1uD41gFBMQ2NeKVryyzJ2Jx4REdFux6D0lMK6hj/v+GXcY1HWikkDF8d78LHGtoTBJ9/hxjsqW1NdJhERET0BbuZ+jGboGA7OYSrBXWhr3ZgaTPraUUOHYdpDnIiIiLYbzigtk1Li1aFO/GjwLiQAQ0qUuHLw6y2nUJ9bbPq62cjiprNJK4qcHqiC2ZSIiChb8Kf2slcG7+EHA3cQ1mNLHbENHaOLfnz59t9hIrRg+roKTz4c6uZ506GoeF/toVSWTERERBZjUMLSctuPBjvidsbWDB2vDN4zfe2Roio4FfOg5FRtsCsK3l29D2fL96SkXiIiIkoPLr0BGA7OwWx/tQGJzrkx09eqioLPHH4B/+bOTxHWNeiGAZuiQIHAu6r3odydh70F5fDanRZVT0RERFZhUMLSrI8hzTdZ2xPMGAGAz5OPL574IO7NjmI8tIBipxeHiiphS9BgkoiIiLY/BiUAFe485NpdmI4EN4zZFRXPVWy+ZKYIBYeKqsBdSERERDsH9ygBEELgN1pPw6GoEHhrDc4uVJS6cnDO15LB6oiIiChTOKO0rDm/DL9/9EX8cPAeHsyNw6nacLaiEecrW+FM4q42IiIi2nmYANao9BbgN3muGhERES3j0hsRERGRCQYlIiIiIhMMSkREREQmGJSIiIiITHAz9xZJKfHQP4FLEz0IxTQcKqrC8dK6pM57IyIiouzCn+5bYEiJr96/gNszw6vnwnXMjuG7/bfxuaMvotDpyXCFRERElEpcetuCyxO960ISAESMGOajYfzVgzczWBkRERFZgUFpC34yfH9dSFphQKJnfgr+aCgDVREREZFVGJS2wB8Nm47ZFBXzCcaJiIgo+zAobUGVJ990TJcGSlzeNFZDREREVmNQ2oL31h6EQ1E3PG4XKk6U1sFtc2SgKiIiIrIKg9IWtBaU48N7noFdUeFUbHAoKuyKin2FFfhY0/FMl0dEREQpxvYAW3TO14LjpfW4MzOMiK6jJb8UFQmW5IiIiCh7MSg9AY/NgZNlDZkug4iIiCzGpTciIiIiEwxKRERERCYYlIiIiIhMcI/SE5BSoj8wg9FFP4qcXjTnl0ERItNlERERUYoxKG3RbGQRf3b3Z5gKB2BICQBw2+z47YPnUZNTmOHqiIiIKJW49LYFUkp8+c7fYXTRj6ihIyYNxKSBBS2CL9x8hUeYEBER7TAMSlvwwD+O2cgiZJwxQ0r8eccv0l4TERERWYdBaQsGA7PQDN10vHdhGmFdS2NFREREZCUGpS3Ic7gSjgsIzEUW01QNERERWY1BaQuOFtcg0b1tAkCuPXGYIiIiouzBoLQFTtWGd1S2xh0TAPYXVcJrd6a3KCIiIrIMg9IWfWTPMRwuqlr3G2cXKkpdOfhk88mM1UVERESpxz5KW6QIgd/a/zb0Lkzj0kQvInoMh4oqcbS4GjZFzXR5RERElEIMSk9ACIE9eSXYk1eS6VKIiIjIQlx6IyIiIjLBoERERERkgktvT0kzdDyYG0dEj2FPXgkKnZ5Ml0REREQpwqD0FK5PDuA/PbqEpeYAEjHDwLGSGnyy5RQ3dhMREe0AXHp7Qn0L0/jrhxcR1mMI6xrCegwxaeDG9BD+e/e1TJdHREREKcCg9IR+NHgv7rlvmqHj4kQvQrFoBqoiIiKiVGJQekL9CzOQJmOqUDAeWkhrPURERJR6DEpPyGt3mI7p0kAOjzIhIiLKegxKT+h8ZSsccTZsCwA+Tx5KXDnpL4qIiIhSikHpCZ0ub0BrQTmcyls3DtoVFW6bA59qPZvByoiIiChVdlV7ACklOufG8IvRR5iPhtGSX4a3V7Y8Ue8jRSj4rf3ncGdmGG+MdWMxFsXBoko8X9HEZTciIqIdYtcEJSkl/vOjy2ifHEDEiAEABgIz+NnIQ/zOofNPdG6bIgSOFFfjSHF1qsslIiKibWDXLL3dmx1F+2T/akgCgJg0EDFi+Pedr8OQZvewERER0W61a4LSL0YfIRKn7xEAhGMaeuan0lwRERERbXe7JijNR0OmY0IIBGKRNFZDRERE2WDXBKXGvFKoQsQdixk6qr0Faa6IiIiItrtds5n7fFUrXh/rgi7XL7/ZhIJ9hb5t2/fIHw3hBwN30T7ZD0NK7C/04QN1h1Dhyc90aURERDverplRKnHl4NMH34EcuxMu1QaXaoddUbG3oAK/ufdMpsuLyx8N4f++/kO8MdaFYCyKkK7h+tQAvnDjVQwEZjJdHhER0Y63a2aUAKAlvwxfOvkyHvknEdAiqM0pRKk7d9PXzUYW4Y+GUOLKSWuPpO/23UZQi8JYc6qcBBAxYvh611V87uiLaauFiIhoN9pVQQlYahTZWlCe1HNnI4v46v0L6AtMQxUqYoaOZ0pq8PHmk3Cq1v/WXZsaWBeS1hoIzCKoRROeOUdERERPZ9cFpWRpho5/ffPH8GshGFJCgwEAuDk1iAUtjN899ILlNejSMB0TAGIyfrsDIiIiSo1ds0dpq65NDmAxFt3QiFKTBnrmpzAYmLW8hpZ885mvfIcbeXaX5TUQERHtZgxKJu7Njqzr4r2WISUe+Scsr+FD9UfgUNQNj9sVFR9ueAbCpN0BERERpQaDkgm3zQGzGKIKkZY9SjU5hfjtg+dR6cmHTSiwKyoKHR78esspHCuttfzzExER7Xbco2TidHkDLo73IBrn2BMDwNE0HYTblF+Kf/Hs++CPhqAbBgqdHs4kERERpQlnlEw05JbgeGndhqUvx/KylzeNbQKApT1JRS4vQxIREVEacUYpgY83n8T+Qh9eG7qPuegiKj35eE/NAbQk2V6AiIiIshuDUgJCCLSV1qGttC7TpRAREVEGcOmNiIiIyARnlLJcKKbh4ngPOudG4bE5cbaiEc15pdzLRERElAIMSllsPDSPP7n5GqJGbPXuvOtTA2grrcUnmk8xLBERET0lLr1lsa90XkAwFlnXwiBq6GifHMSN6cEMVkZERLQzMChlqfHFeYyH5uMemRs1Yvi74Qdpr4mIiGinYVDKUn4tDJsw/9/nj4bSWA0REdHOxKCUpSrcudDidA0HAAGgNqcwvQURERHtQNzMnQJT4QC+3XsTN6eHYEiJxrwSvNxwFI15pZZ9zjyHG0eKq3F7egiaNNaN2RQVL1YfsOxzExER7RacUTIhZbzdPxvNRIL4/I1XcG1qADFpwIDEo/lJ/L93fooHc+OW1vjJllNozi+DXVHhUFS4VBsciopPNp9EXW6RpZ+biIhoN+CM0hr+aAjf7r2J9qkBxAwd1d5C/ErDUewv9Jm+5vv9dxCOaRs2VUcNHV/vuoo/bvt7ltXrVG347UPnMRL0o3dhCi7VjoNFlXCq/N9KRESUCvyJuiygRfD5G69gIRqGsRx7BoOz+POOX+KTLadMjzG5MT20+vzHTYUD8EdDyHe4LasbACq9+aj05lv6OYiIiHYjLr0t++nwAwS1yIbQEzV0fKOrHcZj+4BWJFqiE0LASHIJj4iIiLYfBqVlVyf7EDMJQ5qhYyg4F3fsUFElFMTvgJ1nd6HA4tkkIiIisg6D0rJE8z5CAGYTQ++vOwyHqm543K6o+FhTG48RISIiymIMSsuOldSYNnBUhILqnIK4Y2XuXPzTIy9ib345FCGgQMDnycc/3v88DhVVWVkyERERWYybuZe9s2ovLoz1YDEWXbdPyaGo+HDDUagJumBXevPxu4dfgGbo0KUBl2pfNx7QIrg/NwYA2FtQgRy705ovgoiIiFKKQWlZnsONP3jmJfz37nbcnR2BlECxy4uX64/i2dLapK5hV1TY8dYynJQS3+u/gx8PdUBVloKWbhh4d/V+vL/uEJfliIiItjkGpTWKXV781oFz0A0DMWk8dT+iC2PdeG24E5o0oOlvbRR/bbgTRU4PnvM1PW3JREREZCHuUYpDVZSUNG38/uBdROOcxxY1dPxg8O5TX5+IiIisxRkli8QMHXORRdPx2cgidMNYXZLLFENK3J8bQ8/8FFw2O54tqUWh05PRmoiIiLYLBiWLqEKBXVHjzigBS/uZlAzvUQpoYfx5+09Q5tdRGFOwCOCb9vuoaWrAi41HMlobERHRdsClN4sIIXC6vCFuywGbUHC6fE/GN3P/l1uvo3laojimQsFSa4MyTcVi5wDe6L+f0dqIiIi2AwYlC71c/wzK3LlwKm9N3DkVG8rcuXi5/mgGKwNmIkHkTi7CttxVfEHR0eEM4447jDG7hjudHfjCjVcwEwlmtE4iIqJM4tKbhdw2O/7gmZdwbWoAl8Z7sRiLoiW/DO+q2ge3zb75BSw0HvAjV1/KyR3OMHqdURgAIIABu7b0pEAY/+rGK/jiiZczvpeKiIgoE/jTz2J2RYWUEj0LUxgPLeD1sW78wdXv4Fs9NxIeqGu1IsfShu1xm4Y+ZxSGAFaPrFvz/rwWwfcH7mSiRCIiooxjULJY5+wYvt51FRE9hrCuIaxriEkDPxt9iFeHOjNWV3luAcIq0O2IQt9kq9RPRx5kNNQRERFlCoOSxb43cMe0l9Krg/egSyPOq9KjvrUZIWXzz68ZOiZCC2moKDMMw8D4+Dj6+vowOTnJUEhERKu4R8lig4FZ07GYNOCPhFDk8qaxorccb2jFN4ZvAVJ/a9ktDlUoGQ10Vpqbm8Ply5dhGAaklBBCwG6349SpU8jJyQGwdBSNpmlQFAU2G//KEBHtJvyubzG3zY5oNBZ3TJcyo5u6hRD4B62n8B8eXEj4PLuiosKTl6aq0kfTNFy6dAmx2Pr/P7qu49KlSzh//jzGxsbQ2dmJcDgMACgsLMTBgweRl7fzfj+IiGgjLr1Z7PmKRtjj9FJSINCaXwa3zZGBqt7SVlaHj+551rT5pUNR8asNz0CJ8zVku+HhYdNlNk3TcP/+fdy6dQuhUAhSSkgpMTMzgzfffBPBINsmEBHtBjvvp98282L1fvi8+XAo6upjdkWF1+7Ax5tPZrCyt5yvasWfnHgZ76s5iBKnFwoEVAgUONz4h80ncLaiMdMlWsLv90PX43dO13Ud/f39ccdjsRgePXpkdXlERLQNcOnNYg7Vhs8eeTeuTvbjzbFuaIaBZ0pq8HxFE7z2zM4mrZXrcOED9YfxgfrDCMWi0AwduXZXxruHW8ntdkNRFBjGxv1XZo+vmJiYsLI0IiLaJhiU0sCuqDhTvgdnyvdkupSkuG0OuDNdRBrU1NSgq6sr7pgQIuHdbzs5QBIR0Vu49Ea7ltvtxuHDh6EoymrwURQFqqri2WefhdsdPy4KIVBZWZnOUomIKEM4o5RCi7Eo2icHcG92BGOL87ArKtpK6/A2XxM8Gd60TfFVV1ejqKgI/f39CAaDyMvLQ21tLVwuFw4fPowrV66sW4JbaR/Q1NSUwaqJiChdhBXN9dra2mR7e3vKr7ud/WL0Ef6m+xpicfoN5dic+L+OvQf5Tk8GKqOnMTs7i/v372N2dnZ1Jqm1tRUulyvTpRERUYoIIa5JKdvijjEoPb2Hc+P4/+7+LG5IWpFjc+DzJz4Il5rZw3CJiIhovURBiXuUUuBbfTcThiQACMSi+EbX7gmPREREOwGDUgokOqZkrWtTA4jo8bt0U3zRaBRDQ0MYHBxEKBTKdDlERLTLcDN3ChhIbvlSgcB8NIRSd+66x+ejYdydHYEhDewtqECJK8eKMrPOw4cP0dXVtXpHmpQS1dXVOHToEG/PJyKitGBQSoE8mwtz2uazHQYkch1vbQKWUuJ7/Xfw6lAHVKFALv93vLQeH28+sSOPDUnW8PAwuru7NzR9HB4ehtvtRnNzc4YqIyKi3WT3/iROoXdX78Nm8xs2oeDZktp1m7mvTvbjteFOxKSBiBFD1NChGQbaJ/vxw4F71ha9zT18+DDu8SG6rqOnpydhM0giIqJU4YxSCpyrbEb71AAGAjNxN3U7FRt8nnx8rKkNi7EofjHyCJcn+zARWoAe5/lRQ8dPhu/jvbUHdvyskqZpmJqagpQSxcXFcDqdAIDFxUXT1+i6Dk3T4HCwNxUREVmLQSkFbIqKf3L4nbgy2Yc3xroR0jXU5xTBY3NAVRTsL/ChJb8MC1oEX7jxCgKxCDQj/mGsKzRDR1CLrluq22l6enpw//59KMpSGDQMA3V1ddi/fz/sdjui0ajpa202/tElIiLr8adNiqiKgtPle3A6wXlu3+67iXktBD3JZSOXbef2XBodHcWDBw9gGMa6fUgDAwNwuVyora1FT0/Phj1KiqLA5/OthisiIiIr8adNGl2d7E8qJNmEgrbSOtgVNQ1VZUaiPUhdXV1oampCfn4+VPWt3wNVVeF2u3HgwIF0lkpERLsYZ5TSREq56XIbsLSfqdDpwUcbn01DVZkTCARMx3Rdh67rOHPmDMbHxzE8PAzDMFBZWYmKiop14WmnkVKy9QER0TbCoJQmQghUefIxvOiPO+5UVBwsqsKxkhocLa6GbQfPJgFIag+SEAIVFRWoqKhIY2Xpp+s6Hj16hP7+fmiaBpfLhebmZtTW1iIYDOLhw4eYnJxc+jNUVYWmpqbVTe9ERGQtBqU0ernhKP6i840NM0sORcXHm0/ieFl9ZgrLALM9SEIIlJeX7+hZo7WklLh06RL8fv/q70U4HEZHRwemp6cxPj6+bomyr68PIyMjeNvb3sawRESUBtyjlEaHiqrwD5qOw6Pa4VJty292fLjh2K4KSQDQ3NyM3NzcDXuQXC4XDh48mMHK0mtiYgLz8/MbAqOu6xgZGdmwj0tKiWg0iocPH6azTCKiXYszSml2unwPTpTWoz8wAwmJupyiHb/MFo+qqjh79ixGR0cxNDQEKSV8Ph+qqqp21a3/8cLQZqSUGB4exqFDhyyqioiIVuyen0jbiKoo2JNXkukyMk5RFFRVVaGqqirTpWQddiYnIkoPLr0RZZDP53ui/VjFxcUWVENERI9jUCLKoLKyMni93g0NNFVVRXFxcdwQpaoqWltb01UiEdGuxqBElEGKouDMmTOoqamBqqoQQsBut6O5uRmnTp3C4cOH4XQ6oaoqFEVBTk4OTpw4gfz8/EyXTkS0Kwgr9jq0tbXJ9vb2lF+XaCeTUkLX9dXAtPbxxcVFKIoCt9udwQqJiHYmIcQ1KWVbvDFu5ibaJoQQce/4E0LA6/VmoCIiIuLSGxEREZEJBiUiIiIiEwxKRERERCYYlIiIiIhMcDM3pZQhJa5NDeBnww+woEVQn1uMl2r2o8pbkOnSiIiItoxBiVJGSom/vP8G7syMImrEAABT4QBuTg/iN/eexZHi6gxXuL1IKXFvdhRvjHVhMaZhX2EFnq9oQo7dmenSiIhoGZfeKGXuzY7izszIakgCAAMSUUPHXz24iJixtcNfdzJDSvyH+2/gLzrfwI3pITzwj+MHA3fxh+3fw+iiP9PlERHRMgYlSglN0/C9+9cQNQ1DEvfnxtNa03bWPtm/buYNADRDx2Isiq90vpHByoiIaC0GJXpqUkpcvHgRC5HFBE8CQrqWvqISCAaDGB8fx/z8fMZq+NnIw3Uhaa3JcABji5mrjYiI3sI9SvTUJiYmEAwGUWJTMavqMMTG5+gw0JCb2RPvo9Eorl27htnZWSiKAikl3G432trakJOTk9Za5rWw6ZhNKAhoYQB56SuIiIji4owSPbXx8XHouo66qAOKBPDY8YEqBA4WVqLEld4wspaUEpcuXcLMzAwMw0AsFoOu6wgEAnjzzTcRi8Wf3bFKfW4RBOIkSiwtwVV4GJKIiLYDBiV6aoqy9MfIKRWcDXqRYyhQJWCTgCKBvZ5ifGrv2YzWODs7i2AwiHiHQOu6juHh4bTW81L1AdiVjX/97ELFs6W1yLG70loPERHFx6BET62qqgqqqgIA8gwV7wjk4PmAFyeCHrw7mIf/df/zsCtqRmucm5uLG5KApaA0MzOT1npqcgrxqdYzcKk2uFQbnIoNNqHgYJEPH28+mdZaiIjIHPco0VMrKChAWVkZJiYmoOtLd73lGipUVUV9fT3cbneGKwQcDgeEiL/UtTKebkdLavCnRZW4PzeGcExDQ15JRpcniYhoIwYlempCCBw7dgz9/f3o6elBJBKBx+NBU1MTKisrM10eAKC8vBy3b9+OO6YoCmpqatJc0RK7ouJQUVVGPjcREW2OQYlSQgiB+vp61NfXZ7qUuOx2O44cOYJbt25BSrm6DKeqKhoaGpCXx83TRES0EYMSWapnfgo/GLiLvsA0PKoD53xNOFfZkpE9S1VVVcjNzUV3dzcWFhbgdrvR0NCAkpKStNdCRETZgUGJLHN9cgB/9fAitOVu3QEtgr/tv43r00P4vUMvQI1z15fV8vLy8Mwzz6T98xIRUXbiXW9kCd0w8LVHl1dD0grN0DEYmEH7VH+GKiMiIkoegxJZomt+EvLxzpPLooaON8a601wRERHR1jEokSWWzjEzvx0/oqe3EzYREdGT4B4lskRDbglijy27rbALFYeKzNsGSCnRszAFfzSESk8Bj/MgIqKMYVAiS+TYnXiuoglvjncjuiYwCQB2VcXbfS1xX9ftn8S/vfdzhHVt+fkC9blF+D8OvB05dmc6SiciIlrFpTeyzEcbj+F8ZSscigqnunRER31uMT535N3IdWw8y2wytIAv3X4NIV3Dytm6BiR6Fqbxb+78XdrrJyIi4owSWUYRCl5uOIr31R7EVDgAj82BAqfH9Pl//fCiyfZvYDg4h/6FGdTlFllTLBERURycUSLLOVQbKr0FCUMSAPQuTJuOSQC9C1MproyIiCgxBiXaNgxpNp+0xKVyApSIiNKLQYm2jXJ3bsLxYyW1SV0noEXQ5Z/A2OJ8KsoiIqJdjP9Ep23jI3uO4d91/DLuzNL5ylY4NplR0gwd//XRFbRP9sOmqNClgWJXDv7R3rOo9BZYVTYREe1gDEq0bRwqqsLHm07gG93tiEkDUkoIIfDOyr341T2bn8/21w8u4vbMMDRpQNMNAMDooh9fuv0a/uWz7497px0AzESC+F7/HVyfGoQhDbQWVOBD9YdR7S1M6ddHRETZh0GJtpUzFY04UVaPnoVpSCnRkFu86UwSAEyHg7g1PYSYNDaMabqB18e68N7agxvGZiOL+H+uv4JQLApj+Z67OzPDeDA3hs8cfgENuSVP/7sHa44AACAASURBVEUREVHW4h4l2nZsioqW/DK0FpQnFZIAoG9hGjYl/h9nTeq4Nzsad+y7/bfXhaQVUUPH17uubq1wIiLacRiUaEdwbhKovDZH3MevTw1uCEkrhoN+BLXIU9dGRETZi0GJdoS9BeUQJofwOhUbnvc1xR0z4izVrRAA9ATjRES08zEo0Y5gU1T8RutpOBR1XWByKCr2F1bgQGH8Q3j3FlSYXrPA6UGuPf4GcCIi2h24mZt2jCPF1finR9+NVwY70LswjTy7E++obEVbaR0UEX+26UP1R3B/bmzdwb0AYFdU/NqeYxAmryMiot1ByE26IT+JtrY22d7envLrElmhb2EaX++6iqHgHASWZpJ+bc8xHCmuznRpRESUBkKIa1LKtnhjnFGiXa8+txh/8MxLCGoR6FIi1+7kTBIREQFgUCJa5bU7M10CERFtM9zMTURERGSCM0pEj9F1HaOjo1hYWIDb7UZlZSUcjvh9mFL9efv7+9Hf3w9N01BYWIjm5mYUFPCcOiKiTGFQIlrD7/fj0qVLMAwDuq5DVVV0dnbi2LFjKC8vT/nnk1IiEAjAMAzcvXsX8/Pz0PWlO/DGx8cxOTmJY8eOoaLCvI0BERFZh0GJdqWVWaOZmRk4nU5UV1fD7Xbj8uXL0DRt3fMA4Nq1azh//jxcrtT1VRodHcXdu3cRi8VgGEuHAD/OMAzcunULZWVlUEyOaCEiIuswKNGuEwwGceHCBei6Dl3XIYRAd3c3KisrV4NRPIODg2hubk5JDZOTk7hx4wYMY/PO31JKzM7Oori4OCWfm4iIksegRLuKlBJXrlxBNBpd95iUEsPDw6avMwwDgUDAdDwajUJKCaczuTvnOjs7kwpJKxIFOCIisg6DEu0qfr8f4XA47piU0rR/kqIoCIVC+PGPfwxd15Gfn4/W1lZIKXH37l0sLi5CSgmPx4ODBw+itLTUtAYpJebn55Ou2TAMbugmIsoQBiXaVUKh0BM1kzQMA7Ozs6v7iGZmZnD58uUNs0LBYBBXr17FiRMnUFJSYno9IUTcPUmPU1UVNTU1abnrjoiINuLuUNpVvF6vaUARQqCsrAx2ux2qqgJYmkkSQsQNNmZLZ4ZhoLOz07QGIQR8Pl/COm02G1RVRX19PQ4cOJDwuUREZB3OKNGukpeXh5ycHPj9/g1jQgi0trbC6/Wu66PU19eXcH9SPH6/H4ZhmN6ptm/fPkxNTUHTtNUAJoSAzWbD8ePHYbPZ4PV6VwMbERFlBoMS7TrHjx/HxYsXEQ6HV3slSSlx+PBh5OXlAQCqq986ELe3t3fLn0MIgUAggP7+fvj9frjdbjQ0NKCoqAgA4Ha7ce7cOfT09KxuIvf5fGhsbExpCwIiIno6Ipl9ElvV1tYm29vbU35dolSRUmJychLz8/Ow2+3w+Xym+4A6OzvR29u7pbvU8vLyEAwG1/VHUlUVjY2NaGlpScnXQEREqSGEuCalbIs3xj1KtCut7EdqampCXV1dws3SDQ0NcZfAVvYvPU5VVQQCAei6vm5fk67r6OrqwsLCQmq+CCIishyDEtEmXC4XnnvuORQXF0MIAUVR4HA4sH//fpw7dw6VlZVQVRWqqsLn86GlpcX0zjrDMDAwMJDmr4CIiJ4U9ygRJcHr9eL06dPQNA26rsPpdK6GoWPHjq17bm9vb8Jb/836OBER0fbDoES0BXa7HXa7PeFz8vPzTWeUVFVd3dBNRETbH5feiFKssLAQXq83blhSFGXdHXVERLS9MSgRpZgQAidPnkRBQQEURVltHul2u3H69OlNZ6RSaXFxEdPT0wiFQmn7nEREOwmX3ogs4HQ6cfbsWSwsLCAQCMDlcqGgoOCJjk95EuFwGNevX8fc3BwURYFhGCgsLMSxY8eSPriXiIg4o0RkqdzcXPh8PhQWFqYtJEkp8eabb2J2dhaGYSAWi8EwDMzMzODixYtJnTFHRERLGJSIdpjx8XFEIpENgUhKiVAohMnJyQxVRkSUfRiUiHaYmZkZ6Loed0zXdczOzqa5IiKi7MWgRLTD2O1202U+IURaN5MTEWW7TYOSEGLDd1UhRIk15RDR06qsrEwYlHw+X5orIiLKXqZBSQjxDiHEEIARIcSPhRD1a4Z/bHVhRPRkvF4vmpqaNpxPp6oqWlpa4Ha7Lfm8UkoEg0GEQiHMhIP4fv8dfPX+Bfxo8B7mo2xPQETZKVF7gD8B8KKU8p4Q4sMAXhNCfFxKeQlAem7fIaIn0tLSgqKiInR3dyMYDCInJweNjY0oLi625PONjIzg3r17iEajkFIiCgN3PREM2zXYp4bww4G7+Mf734b9hZzNIqLskigoOaSU9wBASvk/hRCdAL4lhPgcAN5fTLTNlZSUoKTE+lXy0dFR3Lx5E4ZhrD7mgIJnFl1wOQW6XVFAAv++43X8ycmX4bIlt0dK0zT09/djZGQEwNKSYl1dHfdYEVFaJQpKmhCiQko5BgDLM0svAPg+gMa0VEdE25qUEh0dHetC0goBgX0RJ4YdGsLK0r+t2qcG8FzF5t8+IpEIXn/9dUSj0dVrBwIB9PX14fnnn2fTTCJKm0SbuT8HoHztA1LKIQDnAHzRyqKIKDtomoZwOJzwOTXRpRmgiBHDXGQxqet2dHQgEomsC2CGYSASiaCzs/PJCyYi2iLToCSl/ImU8lacx/1Sys9bWxYRZQNFURJ2+hYQyDGWvs04VRsqPHmbXlNKiZGRkbjXTTRGRGQF9lEioidms9mQk5NjOm5AYkFZmhWyKyqOFldvek0pZcIgFG+Zb61YLAZN0ximiCgleCguET2VZ555Bq+//nrcMQPAhNtAns2F3zl0HjZFjfu8tRRFgcfjweJi/GU6r9e7rk+UlBJTU1OYmJjA+Pg4FhcXIYSAx+PB/v37UV5eHvc6RETJSKbh5EeSeYyIdqf8/HycOHECivLYtxMh4G6swj/cdwZfPPkhVHkLkr5ma2vrxuthqRfU3r17Vz8OhUL4+c9/jvb2dvT29q6Gq5WeTteuXcPY2NiTfWFEREhuRun3AfyPJB4jol2qrKwML730EsbGxhAIBOB2u+Hz+WCzPdmkdVVVFaLRKO7fv79u9mjv3r2rncWllLhy5QoWFxdNl9kMw8C9e/dQXl5u2q2ciCgR0+9iQoj3AHgvgCohxJ+tGcoDELO6MCLKLoqioLKyMmXXa2hoQG1tLebm5gAABQUF67qN+/3+hCFpRSQSQSQSgcvlSlltRLR7JPrn3giAdgAfAHBtzeMLAH7XyqKIiIClpTazbuKBQCDp63A2iYielGlQWm4NcEsI8XUppZbGmoiINpXsmXVer5cNKonoiSWzgeCEEOKPANQtP18AkFLKPVYWRkSUSFFREex2O3RdN32Oqqo4ePBg3LFIJIIHDx5geHgYhmEgPz8fe/fuTcuxL0SUPZLpo/RVAF8G8ByA4wDaln8lIsoYIQROnDgBu92+bu/SipKSEpw+fTru0l00GsXrr7+OwcFB6LoOKSXm5uZw5coVjI6OpqN8IsoSycwo+aWUP7K8EiKiLcrLy8MLL7yAoaEhzM3NweVyoaamBl6vN+Hrent7EY1GN2wENwwDd+7cQUVFBfc1ERGA5ILSz4QQXwLwLQCRlQellNctq4qIdq27MyN4dbADk+EASlxevFizH4eKqkyfb7PZUF9fv6XPsbLcFo+u61hYWEBe3ubHrRDRzpdMUDq5/GvbmsckgPOpL4eIdrPv9d/Gj4c6ETWW9h3NRhfR3/kGXqjaiw/VH0lbHZsdk0JEu8emQUlK+Y50FEJEu9tUOIBXhzqhGTpUCdRHHKjR7FClwEiwB0N5laguKk36euFwGLFYDB6PZ0OX7/LycvT19cXtwSSE4GwSEa3aNCgJIcoBfAFApZTyPUKI/QBOSym/anl1RLRrXJscgCElVAk8H/DCYyhQsbRPqCYqcPPNy4js24eGhoa4x5usCAQCuHnzJubn5yGEgBACjY2NaGpqWt131NjYiKGhIWja+s4nqqpi3759Ca9PRLtLMt8N/iOAVwGstNx9COB3rCqIiHansK5BlwYaI451IQkAxPL7nZ2duHTpkunSWDgcxhtvvIG5uTkYhgFd1xGLxdDV1YUHDx6sPs/lcuG5555DaWnpaphyu904fPgw6urqrP1CiSirJLNHqURK+TdCiN8HACllTAhh3riEiOgJNOeXwTn8ALVRx7qQ9Li5uTn09fVhz56Nrdx6e3vjhihd19HT04OmpqbV8+e8Xi9OnjwJXddhGAZsNhvvdCOiDZKZUQoKIYqxtIEbQohTAPyWVkVEu87eggqUuLwJQxKwtNG6r68v7tj4+LjpbJOiKKvnxq2lqirsdjtDEhHFlUxQ+gyA7wJoFEJcAPA1AJ+2tCoi2nUUIfB7h98JzWWDgcQH3T6+t2hFvMaTK6SUCceJiOLZNCgt90s6B+AMgP8NwAEp5W2rCyOi3cdrd+KltjNQReJvTWZ3pdXU1JiGIVVVUVBQ8NQ1EtHukuytHScAHAFwDMDHhBCfsK4kItrN8vPzcfLkyYSBp6WlJe7YSlfux+9aUxQFR44c4fIaEW1ZMu0B/jOARgA3Aaxs4pZYWoIjIkq5kpISvPjii7hx4wbGxsagKAqEEJBS4tChQ3HPbwOWQtTZs2fR09ODgYEBxGIxFBYWorm5GYWFhWn+KohoJ0jmrrc2APtlvM5sREQWURQFzz77LMLhMGZnZ6GqKoqLizfMNK0caDs8PAxd11FeXo7GxkY0NzdnqHIi2kmSCUp3AVQA4JHaRJR2LpcLPp8v7piUEjdu3MD4+Dh0fWnCe2RkBG63G2fOnIHD4djy51tYWMDo6ChisRhKSkpWey0R0e6UVB8lAB1CiCtYfyjuByyriogoCQMDA+tCErDUMykYDOL27dtoa2tL8Or1pJS4d+8eBgYGIKWElBL9/f3weDw4c+YM7Ha7FV8CEW1zyQSlP7K6CCKiJ9HT07MuJK2QUmJiYgKapiUdcEZHRzE4OLiuD9NK6Lp169aWQhcR7RzJtAf4BYD7AHKX3zqXHyMiyqhIJGI6JoRANBpN+lpdXV1xQ5dhGJiYmNjStYho59g0KAkhfg3AFQAfAfBrAC4LIT5sdWFERJvxeDymY1JKuFyupK8VCoVMxxRFQTgc3lJtRLQzJNNH6Z8BOC6l/KSU8hNY6qn0h9aWRUS0uebm5rj9lhRFQXV19ZY6cScKXYZhwO12P1GNRJTdkglKipRyYs3H00m+jojIUj6fD3v27IGiKKtvK20EDhw4sKVrNTU1xQ1WQghUVFRwMzfRLpXMZu5XhBCvAvjG8scfBfBD60oiIkpea2sramtrVw/ELSkpMT3iJBGfz4e5uTn09vau3vWmqipyc3Nx+PBhCyonomwgkukjKYT4FQDPARAAfiml/Hai57e1tcn29vbUVEhElEaLi4vr+igVFRWxjxLRDieEuCaljHtrazIzSgDwJpaOLzEAXE1VYURE243H40FjY2OmyyCibSKZu95+E0t3vb0M4MMALgkh/herCyMiIiLKtGRmlP5PAM9IKacBQAhRjKUZpr+ysjAiIiKiTEvm7rUhAAtrPl4AMGhNOURERETbRzIzSsNYajL5HQASwAcBXBFCfAYApJRftrA+IqJtxTCM1TviHhfWNVwe78O1iX7EwhE0Ci8OFvhQV1e3peaXRLR9JBOUupffVnxn+dfc1JdDRLQ9zc/P4969e5iZmYGUEnl5edi/fz9KSkoAAHORRfyrm68iqEWgyaXz4vqkHzdGJnC6pxsnj59YfS4RZY9Ng5KU8o/TUQgR0XYVCARw4cKFdWfBzc/P48qVKzh+/DhKS0vxnx5egj8awtqGK7oAptUYutUQ1PZ2vOtd79pSt3Aiyrxk7nprE0J8WwhxXQhxe+UtHcUREW0H9+/fNz0w9969ewhqETz0TyBeVzpDAL2OKKSUGB8ft75YIkqpZJbe/iuW7ny7g6U+SkREu8rk5KTpWDAYxGwwAFUoiMn43yKjYqnTNw/WJco+yQSlSSnldy2vhIgoSxW6PJBx55OW5BkqhBDIzeXWTqJsk0x7gH8hhPhLIcTHhBC/svJmeWVERNtEeXm56VhOTg68Ljfe7muBXdm4/0iVQEvECYfDwc3cRFkomRml3wCwF4Adby29SQDfsqooIqLtpLW1FRMTE4jFYuseV1UVBw8eBAB8qOEI5rUw2if7AWPpW6UEcCDiRp0jD6dOneKZcURZaNNDcYUQd6SUh7ZyUR6KS0Q7TSAQQGdnJyYmJiClRFFREfbt24fCwsJ1z5sJB/FgbhyhQADVqhdFufkoLi5mSCLaxp72UNxLQoj9UsqOFNdFRJQ1cnJy4PP5MD8/j1AoBL/fj6GhIeTk5MBut68+r8jlxemKPRmslIhSKZmg9ByATwohegFEAAgAUkp52NLKiIi2ka6uLjx69Gi1TYCu6+jv78fg4CDy8vJQXV2Nmpoa9kki2mGSCUovWV4FEdE2FovF8PDhQxjGxtv/DcPA3NwcFhYW0Nvbi+eee27dDBMRZbdN73qTUvYDKADw/uW3guXHiIh2henpaShK4m+Xuq5jcXERDx48SFNVRJQOyXTm/m0sNZ0sW377L0KIT1tdGBHRdrHZTS9rnzc0NGRxNUSUTsksvX0KwEkpZRAAhBD/GsBFAP/WysKIiLaL4uLiuMtu8TzeQoCIslsyDScFgLWHHOnLjxER7Qp2ux1NTU1JbdTOyclJQ0VElC7JzCj9NYDLQohvL3/8IQBfta4kIqLtp7m5GS6XCw8fPjQ9s01VVbS2tqa5MiKy0qZBSUr5ZSHEz7HUJkAA+A0p5Q2rCyMi2k6EEKitrUVNTQ10XUdPTw+6urpWN3lLKbF37174fL4MV0pEqWQalIQQxwGUSCl/JKW8DuD68uMfEEIoUspr6SqSiGi7EELAZrOhpaUFe/bswczMDIClfUzsoUS08ySaUfoSgF+P83gHgK8AOG9FQUT05OajYfx05AGuTQ1AgcCJsnq8o7IFHpsj06XtSDabDWVlZZkug4gslCgoFUsp+x5/UErZJYQotq4kInoSM+EgPn/zFYRjGmJy6Q6tHw3cxeujXfhnz7yEXIcrwxXS1NQUHj58iIWFBTgcDjQ0NKC2tnbTHk1ElDmJ/na6E4x5U10IET2d/9bdjkUtuhqSAECTBua1EP6271YGKyMA6Ovrw9WrVzEzMwNN0xAMBtHZ2Yn29vaEfZpCoRD6+/vR19eHQCCQxoqJCEg8o/QTIcTnAfxzueZvsRDijwH81PLKiChpMUPH3dlRGNj4A1eXElcm+/DxlpMZqIwAQNM0dHR0bOjFpOs6pqenMTk5uWEJT0qJjo4O9PevPwjB5/Ph6NGjEIJdWojSIdGM0u8B2AOgSwjxzeW3LgCtAD6TluqIKCkxw4CME5JWaIZuOkbWm5ycNA02uq5jcHBww+ODg4MYGBiAYRjr3sbGxvDo0SOrSyaiZaYzSsuduD8mhNgD4MDyw/eklD1pqYyIkuZUbSh0eDAdCcYdr/EWprkiWkvXEwfVeOOPHj2K+/hKa4Lm5mbOKhGlQTKH4vZIKb+3/MaQRLQNCSHwcv1ROJSNt6fbFRUvNxzNQFW0YrMjUAoLNwbZUChk+nzDMKBpWkpqI6LEeKsF0Q5xvKwOH9lzDG7VDpdqg0u1wWtz4JPNp7C/kE0QM8nj8cQNQytGR0c3POZwJG7pYLMlc7ACET0t/k0j2kHe5mvGmfI9GAzMQgiBmpxCqIL/HtruAoEAAoHAunPi6uvr0dXVtWEmSgiB6upqthQgShPTv2lCiPNr3m94bOxXrCyKiJ6cTVHRkFeC+txihqRtxOx8OABQFAWRSGTdY01NTXFnoaSUcDqdKa+PiOJL9F30T9e8/83Hxv65BbUQEe1YeXl5pmOGYcDrXd+eTlEUeDyeuBu2e3p6MD4+nvIaiWijREFJmLwf72MiIkqgqakp7llwQgiUlpbC5VrfOT0Wi2F4eDhuM0pd19kigChNEgUlafJ+vI+JiCiBgoICHDx4EIqiQFXV1V8LCwtx9OjGuxJDoVDCfUjBYPxWEESUWok2c+8RQnwXS7NHK+9j+eMG85cREVE8NTU1qKiowPj4OGKxGAoLC5Gfnx/3uU6nM2FLgcdnoIjIGomC0gfXvP+nj409/jERESXBbrejurp60+c5HA6UlJRgcnJyw/KbqqrYs2ePVSUS0RqJOnP/Ip2FEBHRekePHsWFCxcQDodXu3SrqoqKioqkwhYRPT3ToCSE+BnM9yJJKeUL1pRERETA0qzSuXPnMDY2homJCdhsNlRVVaGgoIDHlxClSaKlt38S57FTAD4LYMKacogoFaSUmJqawuTkJGw2G3w+H3JzczNdFj0BRVFQWVmJysrKTJdCtCslWnq7tvK+EOIcgD8E4ATwv0spf5SG2ojoCWiahosXLyIYDK4u13R1daG2thYHDhzgTAQR0RYkPMJECPEilgJSGMDnpZQ/S0tVRPTEbt++jYWFhXUbgA3DwODgIAoLC1FVVZXB6oiIskuiPUpXAZQC+BKAi8uPHVsZl1Jet7w6ItoSTdMwPj5u2qSwu7ubQYmIaAsSzSgFAQQAfBjAr2J9N24J4Hy8FxFR5oTDYSiKYtp/JxQKpbkiIqLslmiP0tvTWAcRpYDL5UrYpNDtdqexGiKi7GfaH18IcVwIUbHm408IIb4jhPgzIURResojoq2w2+2oqKiIe/SFqqpoamrKQFVERNkr0VlvfwEgCgBCiLcB+CKArwHwA/iK9aUR0ZM4fPgw8vLyVg9gFUJAURTU1dXB5/NluDoiouySaI+SKqWcWX7/owC+IqX8JoBvCiFuWl8aET0Jm82Gs2fPYmZmBlNTU1BVFT6fD16vN9Ol0TYhpYRhGFAUhe0iiDaRMCgJIWxSyhiAFwD8oyRfR0QZJoRAcXExioqKMDExgZGRETgcDvh8PjgcjkyXRxmiaRo6OzsxNDQEwzDgdDrR3NyMuro6BiYiE4kCz98A+IUQYgpACMDrACCEaMLS8hsRbWOLi4u4ePEiotEodF2Hqqq4d+8ejh49yi7Pu5Cu67hw4QKCweBq+4hIJILOzk6EQiHs27cvwxUSbU+J9ih9CMDvAfiPAJ6TbzVmUQB82uK6iOgpSClx5coVhEKh1e7cuq7DMAzcvHkTgUAgwxWSVeL10AKA0dFRhEKhDeO6rqO3txeRSCQd5RFlnYRLaFLKS3Eee2hdOUSUCnNzc6Y9k6SU6Ovrw8GDB9NcFVnFMAx0dXWht7cXmqbB6XSisbERDQ0Nq0tqIyMjq6H5cUIITE1NsRkpURyJglKZEOIzZoNSyi9bUA8RpUAwGDQdk1JidnY2jdWQlaSUuHr1Kqanp1d7aEUiETx48ADz8/M4evToptfg/iQic4mW3lQAOQByTd6IaJvyeDwJx/1+P/r6+tJTDFlqdnYWMzMzGxqN6rqOkZGR1WXWqqqq1ZYRjzMMA6WlpZbXSpSNEs0ojUop/2XaKiGilCksLITD4Uh4ZElHRwfKy8vZrTvLjY6Omi6pAcD4+DhycnLg8/nQ3d2NQCCwLlSpqoo9e/bwbkgiE4lmlDgXS5SlhBA4ceKE6QzCiuHh4TRVRFYx27wNALphwJBLoUhRFJw5cwZ1dXWrfy7cbjcOHDiAlpaWtNRKlI0SzSi9kLYqiCjlcnNzUV9fj+7u7rjjhmHwTqcdoKKiAoODg3FnlQxIXJ4dgr/dj7m5OTidTjQ0NOCll14CwL1JRMkwnVFa05WbiLJUYWGh6aySqqooLCxMc0WUasXFxZBuB3Ssn1mKQWJO0ZE7HsDY2BjC4TD8fj/u3LmDa9euZahaouyTaOmNiLJcWVkZ7HZ73JkDm82GioqKOK+ibCKEQHeRQJ8jihgkDEhEIdHtiCDfUKE+totC13VMTk5icnIyQxUTZRceRUK0gymKgrNnz+LKlStYXFyEEAJSSrjdbhw/fhyKwn8r7QQOux3X3RF0uCJQAegAymM2yKhEvO2muq5jYGAAZWVl6S6VKOswKBHtcG63G+fOnYPf70cwGITH44HusuGOfwL2RRX7C31w2+yZLpOewpnyPbg7M4qoEcPKTiWb+R5vAEvnvhHR5hiUiHaJ/Px85OTl4msPL6N9sh+qokAA0KXEhxuewdsreedTtjpQWImW/DI89I8jaixFpRmbDsXk5mVFUTadTYpGo+ju7l49QLekpAQtLS3IzWUbPdpdGJSIdpG/7b2F61MDiEkDMf2tXjrf7L2BUncODhTysNxspAiB3zrwNrwx2o2fjjxAQIugyluAfIcLi7P+Dc0oVVVFTU2N6fWi0Sh++ctfIhKJrLYfGB0dxcTEBE6dOsWbAGhXYVAi2iU0Q8fPRx+tzjisFTV0fL//LoNSFlOFgnOVzThX2bz6mK7ruHv3LoaHh6EoCgzDQE5ODo4dO5awwWR3d/e6kLT2erdv38a5c+cs+zqIthsGJaJdYjayuG4hRjWAfWEninQVUfH/t3dnsXFl+XnAv3NusVauxeJWXEVxlail2SK7Wy11j2ZGY0ziwHEyyQB58ALYRvIUIzD8EDj2xI4DGA4COAkMBDGMBIkxMODYcIDxON1xT3dLra3VrY2URHHfdxZZrCJru/fkgWQNqapbRVJFFln1/QBCYt2l/iUJza/POfd/FEaN9azVRkdD0zRcunQJnZ2dCAaDsFqtcLlcSc9VSmF2dhZDQ0Pw+/2m9wwGgwiFQrDb7UdVNtGJwqBElCdcFhv07S7N7pjE1eDWD0wBAQUFzzrw5ZdfoqenJ5tl0hGwWq1ptyh5/vw5JiYmUm6HAmy1I0h3DlEu4bPBRHnCVWBFe2kVpBJ4d1dI2vlVQGB+fh6Tk5PZLJOyIBgMYnx8fF8BSNO0tJsuE+USBiWiPPILre+gRTkgrMi20AAAIABJREFU8dOQ9Lrnz58fb1GUdbOzsyn3jNshpURnZye3PqG8wqBElEdKbU58x9NqGpKArf46+/mhSblD1/W0f+dWqxUXLlxI+bQcUS5iUCLKM+X7eLQ7FAodQyV0Ung8npR7Al66dAk3b95kSKK8xKBElGe83vQtADi1kvs2NzcxODiIZ8+eIRgMoqioKGFLGyEECgsLUVdXx38TlLf41BtRHqqqqsL8/HzSY4WFhXz0O8dNTEygr68PAGAYBjRNgxACHo8HS0tL8T0Bq6urceHCBYYkymsMSkR56MKFC1hZWUnY70vTNFy4cCFLVdFxCAQC6Ovr29Ote+dpN7/fj5s3byIcDsNms6GggHsAEnHqjSgP2e12fPDBB6irq4OmaZBSwuPx4L333kN5eXm2y6MjNDY2ZrpwOxqNYm1tDYWFhQxJRNs4okSUpxwOBy5fvozLly9nuxQ6RoFAIOUTbpubm8dYDdHJxxElIqI8UlxcnHLNkdkWJ6kopbCwsIDR0VHMzc0lbMJLdJpxRImIKI80NTWZTr/Z7XaU7aN9xG6BQAD37t2L99+SUkJKid7eXpSWlmaqbKKs4YgSEVEecTqdeOuttyCljPdO0jQNdrsdvb29B3rCzTAM3L17F6FQCLquwzAMxGIxRCIR3Lt3D7FY7Kg+BtGx4YgSEVGeqampgcfjwezsLMLhMIqKilBZWZnQRymd+fl50zCklML09DQaGxvj3y8uLiIQCMBut6Oqqsq0ySXRScKgRESUhwoKCtDQ0PBG9wgEAqYb6eq6Dr/fHz9v9/ScEAJCCPT29sLtdr9RDURHjVNvRER0KHa73XRUSEoJh8MBpRTu3bu3Z3pO13XEYjHcv38fkUjkmKsmOhiOKBFRUpFIBCMjI5idnQWwtfXJmTNnYLVas1wZnRQ1NTXxDt/J1NXVYWFhIaGx6Q6lFKamptDc3HxUJRK9MY4oEVGCUCiEzz77DCMjIwgGgwgGgxgeHsZnn33GDXMpzmKx4O233443LQUQf+rt0qVLsNvtCAQCpu0CDMOIT88RnVQcUSKiBP39/QiHw3teMwwD4XAYz58/R3d3d5Yqo2zbWWO0o7KyEjdu3MDExATW19fhcrnQ2NgIh8MBYGt6TkqZdC2TlBJOp/PYaic6DAYlItpDKYW5uTnT47Ozswk/LCn3zc/PY2BgAH6/H1JK1NbWoqOjAzabDXa7HW1tbUmvq66uxrNnz0zvW19ff1QlE2UEp96IaA+lVMotLtIdp9wzNTWFr776Kj5NZhgGpqamcOvWLdP1Rzs0TUNPT0/S6bmLFy/GR56ITiqOKBHRHlJKuFwuBIPBpMcLCwsP3G+HTi/DMNDf35+wzkgphUgkgrGxMbS2tqa8R3l5Ob71rW9hcnISfr8fTqcTDQ0NDEl0KjAoEVGCzs5OPHr0KGFdiaZp6OzszFJVlA1ra2umI4iGYWB6ejptUAIAq9WKs2fPZro8oiPH/y0kogTV1dXo6upCQUEBLBYLLBYLCgoK0NXVhaqqqmyXRycIp2Ep13FEiYiSqq+vR21tbXxdSnFxMafc8lBxcbHpMSklvF5vxt7L5/NhcHAQa2trKCgoQFNTExoaGvjvjrKK//qIyJSUEqWlpSgtLeUPqzylaRo6OjqSduC2WCw4c+ZMRt5nenoa9+7dw8LCAsLhMAKBAF68eIEHDx5w1Iqyiv/lIyKilJqamuJPqO3s01ZdXY3r169npFO7rut49uxZwpo4Xdfh8/lStqsgOmqceiMiorRqa2vh9Xqh63r88f5MWV5eNj2m6zomJydRU1OTsfcjOggGJSIi2hchBCyWzP/YiMVib3Sc6Chx6o2IiLLK7Xab7gcnpETEZcXL1TkYKvk5REeJI0pERJRVdrsdXq8XMzMzewKTAhBROj5ZH0Hs+QgsUsO/6LyOlpLK7BVLeYcjSkRElHUXL15EY2MjpJSwWCwwBLCq6bjlCiCgYgjpMQSiYfynvk/hC29ku1zKIwxKRER0ZCKRCCKRSNrzpJQ4f/48vvOd76D9rYv4rHgDtwuD2ND2tgaIKQM/mRk4qnKJEnDqjYiIMm5lZQV9fX1YX18HALhcLnR1dcHj8aS8zmKxYEXGEJUAkixJ0pWBF745IDPtm4jS4ogSERFl1OrqKu7fvw+/3w+lFJRSCAQCePDgAZaWltJeX1hgQ9TQTY/7Ipx6o+PDoERERBn14sWLhOaRwNYmus+fP097fWtJBQyYd+MORMMpgxRRJjEoERFRxiilUjaQ9Pv9mJycTNkbSQoJkeZ9YibtBIgyjUGJiIgySojUMaevrw8fffQRJicnTc85U2S+lsljL4TDUnDo+ogOgkGJiIgyRgiBqqqqlOfoug7DMNDX1wefz5f0nJ8/cxkFMnEj3gKp4XvN3RmplWg/GJSIiCijOjo69rXVia7rGBoaSnqsraQS/7zzOtw2J6xSg1VqKC6w4xda38Hl8rpMlxynlIKu61DKfI0U5Re2ByAioowqLCzE9evXMTAwgLm5OdPtSYCtNUtmutxe/Puen8NCaB1KKVQ6iiHTTOsdllIKQ0NDGBkZQTQahaZpaGxsRHt7OzQtcWSL8geDEhERZZzL5UJ3dzc2Njbw6aefmoYlu92e8j5CCFQ5io+ixD0eP36M2dnZeJ26rmNsbAyrq6t477330q67otzFqTciIjoyTqcTxcXJg44SAi8tm/jfI4+wFAocc2U/tb6+vick7TAMAysrK/jxj3+MR48eYWOD/ZvyEYMSEREdqe7ubthstj1TWDEoTFkieBBewN/NDOAHX/0IXy9OZKW+xcXFlGuSDMPA9PQ0Pv/8cwQC2Qt0lB0MSkREdKScTidu3LiBzs5OlFdWYMoaxT3XBh47NgGxtS1J1NDxp6/uIhgNZ6XG/UytxWKxfTXMpNzCoEREREfOYrGgqakJwdoS9Dkj8Fl0vN5VUgD4cnH82GurrKzc97npRp8o9zAoERHRsfGFNxBVybcfiRg61iKbx1zR1lN6Xq93X0+37exdR/mDQYmIiI5NQ2EZbDL5A9c2zYI6V9kxV7Tl0qVLaGtrg81mS3leSUkJpOSPznzCv20iIjo23Z6GpB23BQCbtOBSea3ptYZhYHZ2Fk+ePIl39c7U6I4QAmfPnsXNmzfx7rvvJg1DUkp0dnZm5P3o9GAfJSIiOjYFUsNvXPo2/ujZT7ChR6CUghAChRYb/mXXDViShCgAiEQiuHPnDjY3N6HrW1N3k5OTqKqqwltvvZXRPkcejwc9PT149uwZQqEQgK1+TxcuXIDHY74HHeUmcRRzrVeuXFEPHz7M+H2JiCg3GErh1do8lkIBVNiL0FZSmTLsPHz4EPPz80lHkAoLC3HhwgWUl5dntEalFMLhrafwbDYbm07mMCHEV0qpK8mOcUSJiIiOnRQCHaXV+zo3Go1iYWHBdJotEAjgwYMHaG1tRUtLS8ZqFEKk7RxOuY9rlIiI6EQLh8NpR3N0XcerV6/YPZsyjkGJiIhONLvdvu9F2zMzM0dcDeUbBiUiIjrRLBYL6urq0j6WbxgGIpHIMVVF+YJBiYiITrzz58+jvLw8ZVjSNA1ut/sYq6J8wKBEREQnnqZpeOedd3D16lVYrdak59hsNlRVVR1zZZTrGJSIiOjUKC0txYcffgi32w0pJSwWC6SUKCsrw9WrV/kIP2Uc2wMQEdGpYrPZcPXqVWxsbGBjYwMOhwMulyvbZVGOYlAiIqJTyel0wul0ZrsMynGceiMiorwXi8UQDocztncc5Q6OKBERUd6am5vDkydPEI1GAWxtfNva2orW1tYsV0YnBYMSERHlpcXFRby+L6lhGBgYGICu6+jo6MhSZXSScOqNiIjy0tOnT02PDQ8PcxqOADAoERFRntrc3DQ9ppTC2tpawuuGYcDn88Hn88EwjKMsj04ITr0RERHtw+TkJPr7+/e81tnZicbGxixVRMeBI0pERJTTzKbQUrUWEEKgpKQk/v3c3Bz6+voQi8X2fPX392N2djbjNdPJwRElIiLKOUopjI+PY2hoCKFQCJqmoaGhAR0dHdA0DQBw6dIl3L17N+n17e3te7p8v3z5ErquJ5xnGAZevnyJmpqao/kglHUcUSIiopzz/PlzvHjxAqFQCACg6zrGx8dx586d+Nqi8vJyvPvuu7DZbPHrNE1DV1cXWlpa4q8ppRAIBEzfKxgMJg1RlBs4okRERDklFAphfHw8YbG1YRgIBAJYWFhAdXU1AMDj8eDmzZvx6TmzveKklKaLt4UQkJLjDrmKf7NERJRTFhcX44FnXeqYsUSxrMWgoKDrOmZmZhKuCcYiuLcwis9nBzG/4d9zTAiBmpoa0xBVXV3NzXhzGEeUiIgopyilEIGBe64gVjUdEoACUKAEejacqHltcffHUy/w1+NPISGgoKAAdJXV4Fc63odFbq1n6uzsxNLSEqLRaHxkSUqJgoICnD9//ng/IB0rjigREVFOqaiowF1HAD5NhyGAmAB0AYSkwl1XECVVnvi5fSsz+D/jTxE1dISNGCKGjqiho883i78YeRQ/z26348MPP0RLSwsKCwtRWFiIlpYWfPjhh7Db7dn4mHRMOKJEREQ5ZUkPYV0zkKwpgALwSvdjZ6n2jyb6EDESF2JHDR2354fx82cuw6Zt/ai0Wq1oa2tDW1vbkdVOJw9HlIiIKKdMBFZMF1frAhheX45/P7eZ2H17hxQCvvBGxuuj04VBiYiIckphgQ3SZHG1gECJ9adTZUUF5tNmumGgqMBmepzyA4MSERHllHNlNRBIHpQKpMQHNa3x779d2wHr9oLt3SQEOkqr4WJQynsMSkRElFMKpIZf67wGq9Sg7RpZskoNN7ztaCoqj792rfoszpfVwCZ/umTXJi0osznxi23vHGvddDIJsz1w3sSVK1fUw4cPM35fIiKi/VoKBfDJzABG/ctw25y44W1DS0llwnlKKbxaW8C9hVGE9SguuuvwdkUDCpKMNFFuEkJ8pZS6kuwYn3ojIqKc5LEX4p82v532PCEE2kur0F5adQxV0WnDoERERLRP08FVvFqbh1VacLm8jmuY8gCDEhERURoRPYY/fv45hvyLABQkJH44/BD/uOkybtS2AwB84Q08W5mGoRTOldWg0lGU3aIpIxiUiIiI0vhfQw8wuLaAmNrZGHfr178ce4waZwn6fDP4ycyrrT3fFAB8jW5PA36p/V1IweemTjMGJSIiohSC0Qi+XpzYFZJ+KmLo+OHwQ6yEg1vHdz0f9Wh5EpUTRfjZxgvHWC1lGmMuERFRCsvhALQUT8DNb64n3QYlYuj4f9MvYSQJWHR6MCgRERGlUGJ1IJYkCO1QSXeV2xI1dGzGokdRFh0TBiUiIqIUSqwOnC2ugEzS7dsqNdi1AtNrhRApj9PJx6BERESUxi+3v4dSmyPewVtgKyS97WnAd2o7kjantAiJdyqboJls0EunAxdzExERpVFmc+J3r/wDfLU4gT7fDBxaAd6tOoPmIg90ZeCVfxGj/iWEjRiArW1QKhxF+CdnurNcOb0pbmFCRET0hgylMLA6jy8Xx2Aohbc89ehye6FttwYIBAIIBoNwOp0oKmJ/pZOGW5gQEREdISkEOsuq0VlWvef1cDiMhw8fYm1tDVJKKKXgcrlw5coVOJ3OLFVLB8GJUyIioiOglMKdO3ewuroKwzAQi8Wg6zr8fj/u3LkDw2DbgNOAQYmIiOgILC0tIRQKIdkSl2g0itnZ2SxURQfFoERERHQEVldXoevJ+y/puo6VlZVjrogOg0GJiIjoCBQUFECatAYQQsBqtR5zRXQYDEpERERHoKamxvSYEAJ1dXXHWA0dFoMSERHREbDZbDh//nzCqJKmaWhra4PL5cpSZXQQbA9ARER0RBobG1FSUoKRkRGsr6/D5XKhubkZbrc726XRPjEoERERHaHS0lJ0d7ND92nFqTciIiIiEwxKRERERCYYlIiIiIhMcI0SERHRCaCUwuTkJIaGhrC5uQmbzYbm5macOXMGQohsl5e3GJSIiIhOgP7+fkxOTsa7eYdCIbx8+RIrKyt4++23GZayhEGJiIgoSwzDwOzsLEZHR7G6upr0+OLiIlZXV1FWVpaFColBiYiIKAt0Xce9e/fg9/tN94TbOW92dhZlZWVQSmF5eRmTk5OIRqOoqKhAfX09LBb+OD8q/JMlIiLKgtHRUaytrcEwjLTnGoYBpRQePXqE+fn5eLBaXl7G4OAgrl27BqfTedQl5yU+9UZERJQF4+Pj+wpJmqahoqIC09PTe0ISsDXaFIlE8PXXXx9lqXmNI0pERERZEIvF0p4jhIBhGPjyyy9Tnuf3+7GxscFRpSPAESUiIqIsKC4uTnlcCAGlFJRSae8lpUQ4HM5UabQLgxIREVEWtLW1QcrEH8NSSjQ0NByoHYBhGHC5XJksj7YxKBEREWVBeXk5Ll68CIvFEv/aCUnV1dVJQ1QyUkrU1NTAarUeccX5iWuUiIiIsqSurg41NTVYWVmBrutwu92wWq1YXFxMe62maVBKwePx4OLFi8dQbX5iUCIiIsqinafadnO73aZrk6SU8Hq9cLvdcLvdKCwsPI4y8xan3oiIiE4YTdPQ3t4OTdP2vC6EgN1uR1dXFxoaGhiSjgFHlIiIiE6g5uZm2O12DAwMIBgMQkqJ2tpadHZ2shP3MeKfNBER0Qnl9Xrh9Xrj03DcGPf4MSgRERGdcAxI2cM1SkREREQmGJSIiIiITDAoEREREZlgUCIiIiIywaBEREREZIJPvREREeWxcDiM0dFRLCwsxPeaq62tTWh2ma8YlIiIiHKUz+fD8PAwAoEAXC4XmpubUV5eHj8eDAZx+/Zt6LoOwzAAAGtraxgaGsK1a9e40S4YlIiIiHLS2NgYXrx4AV3XAQCBQABLS0toaWlBa2srAODx48eIRqN7rlNKYWNjAx9//DG6u7tRU1Nz7LWfJFyjRERElGPC4TCeP38eD0k7dF3H4OAggsEgwuEw1tbWTO+hlMLjx4/h9/uPutwTjUGJiIgox8zMzJgeU0phenoasVgsbcdvwzAwPDyc6fJOFU69ERERnXLBYBBjY2NYX19HYWEhAMTXHL1OKYVIJAKHw5E2KCmlsLq6mvF6TxMGJSIiolNsZmYGjx8/hlIKSiksLy8DAKSUScOSpmlwu92QUuLs2bMYHBw0DVUAYLfbj6z204BTb0RERKdUJBLB48ePYRgGlFIAEA9MhmEkjBgJIVBQUIDq6moAQEtLC86cOWN6f03TUh7PBwxKREREp1SqtUhCCNjtdkgpYbFYIKVEcXEx3n//fUgp4+d0dnbi/fffh6Zpe4KVpmnwer2oqqo68s9xknHqjYiI6JQKh8Mp1yJVV1ejqakJGxsbcDgc8fVLrysrK8O3vvUtTE1NYXFxEVarFQ0NDXC73fHwpJTCzMwMBgcHsbGxAYvFgtraWnR0dOR0c0oGJSIiolOquLgYmqYltAEAtkaESkpK4HK54HK50t7LarWiubkZzc3NSY+/fPkSo6Oj8WAWiUQwOjqK8fFxXL9+HUVFRW/2YU4oTr0RERGdUlVVVbBYko95aJoWX4v0pjY3N/eEpN0Mw8Dt27cRi8Uy8l4nDYMSERHRKSWlxNWrV+F0OqFpWvxLSolIJIK//du/xe3bt+NPwh3W/Px8fLF4Mrqup1wvdZoxKBEREZ1iLpcLN27cQG9vL9ra2gDs7aG0urqK+/fvY3Fx8dDvkSok7VhZWTn0/U8yBiUiIqJTTgiB8vJyBAKBpOuVDMPAs2fP9hV4kvF4PGnPsdlsh7r3ScegRERElCPm5uZMj4VCIYRCoUPdt6ioCBUVFabHhRCor68/1L1POgYlIiIiSuvKlSuorKxMeF1Kifb2dtPWA6cd2wMQERHliKqqKkxNTSU9ZrPZ3mg7Eiklent7sba2huHhYQSDQbhcLpw5cwZlZWWHvu9Jx6BERESUI9ra2jA3N5fwqL6UEl1dXWk3wd2PkpISdHd3v/F9TgtOvREREeUIp9OJa9euobKyMh6KiouL0dPTk/dbkRwWR5SIiIhySGFhIXp7e+Mb5e5sL7K5uYmRkRHouo7a2lqUl5dnudLTgUGJiIgoB+1sfAsADx8+3PNE3MTEBJxOJz744APTzt60hVNvREREOezVq1dJ2wZsbGzg3r17WajodGGMJCIiymHDw8Omx1ZXVxGJRGC1WjPyXpFIBOPj45ibm4Omaaivr4fX641P/51GDEpEREQ5LFmn7t3W19czsl5pY2MDt27dgq7r8S1U1tbWMDY2hqtXr57asMSgRERElMccDkdG7vPkyRNEo9E9r+m6jvX1dYyMjKC1tTXpdeFwGP39/VhcXIQQAnV1dWhpacnYKNeb4holIiKiHJZq6xGr1Qqn0/nG7xGJREw3xTUMA+Pj40mPra6u4uOPP8bMzAyi0SgikQhGRkbwySefHHq7lUxjUCIiIsphb731lumTbe+8807a65VSWFpawtTUFPx+f9JzotHonqfsXvd6A8wdZovJY7EYnjx5kra248CpNyIiohxmtVpx8+ZNDAwMYGpqCkopVFRU4Ny5c2m3NPH5fHj48OGeoFNUVISenh7YbLb4aw6HI2XX75KSkoTX/H6/aYACgMXFRSilMtJN/E0wKBEREeU4TdNw7tw5nDt3bt/XhMNh3L9/PyHMrK2t4cGDB7h+/Xr8NSklmpubMTw8nLB4XEqJtra2hPsHAoEDfors4NQbERERJZiYmIg/vbabUgqBQACrq6t7Xm9tbUVjYyOklLBYLPGvS5cuJX2qrrCwMOX7WyyWrI8mARxRIiIioiR8Pl/SoLTD7/ejtLQ0/r0QAufOnUNLSwt8Ph80TYPb7TZdu1RcXAy73W66aLulpeXNPkCGcESJiIiIEtjt9pQjOrvXKO1mtVpRVVUFj8eTcoE3ANP+SjU1NScmKHFEiYiIiBI0NjbGF3+/TgiRsu3AfjmdTvzMz/wMZmZmMDc3B6vVirq6OiwtLeHWrVvx7t61tbVpQ9dRYVAiIiKiBCUlJWhpacHQ0FB8Ck5KCSEErly5krHgIqVEXV0d6urqEAgE8MUXXyR09x4fH8d7772Xle7eDEpERESUVFtbGyoqKjA2NoZQKITS0lI0NTVlrJv368y6e/v9foyOjmZlOo5BiYiIiEyVlZWhrKzM9Liu6/GRpjcRDoextraW9NhOd28GJSIiIjoVJicn8erVK2xubkJKCa/Xi3Pnzh16j7ZoNJoybKVqTnmU+NQbERERHcjQ0BD6+vqwubkJYGvEZ3p6Grdu3Tp0oEk3nZeJPekOg0GJiIiI9i0Wi+HVq1cJHbiVUohEIpicnDzUfTVNQ3Nzs+nx9fX1eDA7TgxKREREtG8rKyumT7zpuo7p6elD37uqqirl9Nv4+Pih731YDEpERESUMW+yqDsQCJiGMMMwErZNOQ5czE1ERERQSsHn8yEQCMDhcMDj8SQNPW63O2kTSmBr+szr9SY9Fo1GMTU1BZ/PB5vNhoaGBhQVFe05x6zbN7AVwI6qLUEqDEpERER5bmNjA/fv39+z75rFYkFvby9KSkr2nGuxWNDe3o6BgYE965SEELDZbKivr0+4v9/vx507d6CUil8zPj6O1tZWtLa2xs/zeDzQNC1h/dPO/Zuamt70ox4Yp96IiIjymFIKd+/eRTAYhK7r8a9wOIy7d+8mfYqtubkZFy9ejD+JJqVEfX09rl27BovFknD/Bw8eIBaL7QlAhmFgaGgIPp8v/poQAj09PbBYLHum4KSUaG1tTQhtx4EjSkRERHlscXERkUgk6TGlFKamppKO5NTW1qK2tjY+DWe2Nsnn8yV0296h6zrGxsb2NLQsKyvDN7/5TUxMTMDn88HhcKChoQHFxcUH/GSZwaBERESUx/x+f3xftdfpum7aLXuHWUBSSiEcDiMQCKS8fmNjA8DWnm4vXrzA8vIyAKCiogKdnZ0J65iOG4MSERFRHrPb7ZBSmq4LstvtB77n9PQ0Xrx4gUgkAqWU6eJvIQRKS0uxurqKu3fv7qlhYWEBy8vLuHbtWlbDEtcoERER5bHq6uqUx2dmZvDpp59iaGgoaZh63eTkJJ4+fYpQKATDMExDErC19qipqQn9/f1J763rOl68eJH+QxwhBiUiIqI8ZrFY0N3dDU3TEnoYKaUQDAYRCATw8uVLfPTRRwiHw6b3UkrhxYsXKQOVlBKapkHTNHR3d8Nut6fsj7S4uJgybB01Tr0RERHluaqqKnzjG9/A2NgY/H4/1tfX97QK2KHrOr744gt885vfTHqfnSfnzBQUFKCtrQ1WqxVVVVWwWCz7GqXKJo4oERERERwOBzo7O3HlypWkIWnHxsZGfAH269J15dY0DWfOnEFtbW28jYCmaSmfaCsvL3+jbt9vikGJiIiI4vYzwmP2JJzT6TTtri2EQG1tbdJj58+fT7p1iaZp6OzsTFvPUeLUGxEREcUVFBRACJFyXZDVao3/Xtd1TExMYHp6GoZhoLy8HJubm3uuF0LAarXi7NmzSe/ndrvx7rvvor+/H36/HwBQWlqK8+fPZ6XJ5G4MSkRERBQnhEB9fT0mJiaSHrdYLHC73QC29m+7ffs2Njc3472YAoEALBYLCgsL4ff7IaWE1+uNr00y43a7cf369fiIlqZpGf5kh8OgREREWbW+vo6RkRH4fD7Y7XY0NTWhqqoqq+tS8l1XVxd8Ph/W19f3vC6lRE9PT/zv5tWrV9jY2NgzemQYBgzDQEFBAb773e8e+L1PSkDawaBERERZMz8/j6+//jrebycQCGBlZQVerxeXLl1iWMoSKSU++OADzM7OYnh4GNFoFJWVlWhubo7v7wYAU1NTplN0i4uL0HX9xAWfg2JQIiKirDAMA48ePUpYPGwYBqamplBbW4uKioosVUdCCHi9XnjxFLRpAAAH/klEQVS9XtNzkm2Yu/v6XAhKfOqNiIiyIl0jwSdPnhxjNXQYqR7rt1gsKCgoOMZqjgZHlIiIKCtisZjpZqwAEAqFMDAwEA9U1dXVaGxsTLkgmI5Xe3s7vvrqq4RRQU3T0NbWlhNTpxxRIiKirCgpKUm7NcXQ0BBWV1extraGwcFBfPbZZ9jc3DymCimdyspKdHV1wWKxxL+klGhpaUFjY+O+77O5uYm1tbWUU3nZwhElIiLKisLCQthstrR7h+0wDAPhcBjPnj1Db2/vcZRI+1BfXw+v1wufzwelFMrKyuJdt9MJBAJ49OgR1tfXIaWEYRhoaGjAuXPnkjagzIaTUQUREeWlrq6uA0/P7DxNtR9KKYRCoRM5UpFLNE2Dx+NBRUXFvkNSJBLBF198gbW1NRiGEZ+KnZiYwNOnT4+44v3jiBIREWVNdXU1PB4PlpeXU65X2k0IgVgslvJpKqUUxsbGMDg4iFgsBqUUPB4PLl68CIfDkany6Q1MTEwkDbyGYWBmZgbt7e0n4u+KI0pERJQ1Qgj09PSgo6MDDocDmqahpKRkT6+e11kslrQLugcHB/Hy5UtEIpF4j6alpSXcunULkUgk0x+DDmFhYcE0HEsp4fP5jrmi5DiiREREWSWlRHNzM5qbm+OvLSws4OHDhwk/SPfzNFUsFsPQ0FDCtUopxGIxjI+Po7W1NbMfgg4s3RTdfqfwjhpHlIiI6MSprKzEhQsXEp6mOnv2bNqnqXw+n+lCYMMwMDs7exQl0wHV19ennD4tLy8/xmrMnYy4RkRE9JrDPk2VbnH4SXmaKt9VV1fD7XZjZWVlz1olKSUuXrx4Yjp6MygREdGJtfM01UHs7Gxvdr+6uro3LYsyYGd92uTkJMbGxhCJRFBSUoLW1laUlZVlu7w4BiUiIsopUkp0dXXh6dOne9YpSSnhcDhQX1+fxepoNyklGhsbD9Sc8rgxKBERUc6pq6uDzWbDwMAA/H4/LBYL6uvr0draemKmdOh0YFAiIqKcVFFRgYqKimyXQaccV7QRERERmWBQIiIiIjLBoERERERkgkGJiIiIyASDEhEREZEJBiUiIiIiEwxKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjLBoERERERkgkGJiIiIyASDEhEREZEJBiUiIiIiEwxKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjLBoERERERkgkGJiIiIyIRQSmX+pkIsAhjP+I2JiIiIMq9RKVWR7MCRBCUiIiKiXMCpNyIiIiITDEpEREREJhiUiPKIEKJcCPF4+2tOCDG96/vfEUL0CyGebn//zvY1nwohHu66xxUhxKfbv/+GEGJt1z0eCyG+neR9C4UQ/1UIMbz9Hp/v3P+0EkJcFkL8PZNj5UKInwghAkKI/3LctRFR5liyXQARHR+l1DKAywAghPgBgIBS6j8IId4D8B8BdCulwkIIDwDrrksrhRDfVUr9OMltbymlfjbNW/8JgFEArUopQwjRDKDzTT9Pll0GcAXA3yQ5FgLwbwB0bX8R0SnFESUiAoAaAEtKqTAAKKWWlFIzu47/IYDfOsyNhRBnAbwD4LeUUsb2/UeUUj/aPv6vhBB921+/vv1akxDipRDiT7Zf/zMhxLeFEF8IIQaFEL3b5/1ACPE/hRCfbL/+q9uvCyHEH25f+0wI8f3t17+xPUL2F9v3/zMhhNg+9rYQ4jMhxFdCiP8rhKjZfv1TIcQfCCEeCCFeCSGuCyGsAH4XwPe3R9G+v/szK6WCSqnb2ApMRHSKMSgREQB8BKB+Owj8sRDiw9eO3wUQFkLcSHLt9dem3s6+dvw8gMdKKf31C4UQbwP4ZWwFqXcB/KoQ4q3twy0A/gjARQAdAP4ZgGsAfgPAv951m4sA/j6A9wD8thDCC+AfYWvE5xKAbwP4w53gA+AtAL8O4ByAZgDvCyEKAPxnAN9TSr0N4E8B/P6u97AopXq3r/sdpVQEwG8D+HOl1GWl1J8n+XMhohzAoEREUEoFALwN4NcALAL4cyHEL7122r9D8lGlW9thYedr+ABvfQ3AX22PwAQA/CWA69vHRpVSz7ZHofoB/J3a6mfyDEDTrnv8tVJqUym1BOAnAHq37/tDpZSulJoH8BmAnu3zHyilprbv+3j7Xu3YmiL7WAjxePtz1u16j7/c/vWr196biHIc1ygREQBge8TnUwCfCiGeAfhFAP991/FPhBC/h62Rn4PoB3BJCCF3pt52ESmuC+/6vbHrewN7/9v1ejM4dYD76tv3EgD6lVLvpblm53wiyhMcUSIiCCHahRCtu166jOTd9X8fwG8e5N7bI0wPAfzbXeuBWoUQPwfgcwD/UAjhFEK4APw8gFsHLP/nhBB2IUQ5gG8A+HL7vt8XQmhCiAoAHwB4kOIeAwAqthe1QwhRIIQ4n+Z91wEUHbBWIjplGJSICAAKAfwPIcRzIcRTbK3f+cHrJyml/gZbU3O7vb5G6XtJ7v8rAKoBDG2PVv03ADNKqa+xNWr1AMB9AH+ilHp0wNofAPgRgHsAfm97EfpfAXgK4AmATwD8plJqzuwG22uOvgfgD4QQT7A1JXc1zfv+BMC5ZIu5AUAIMYatJwl/SQgxJYQ4d8DPRUQnALcwIaJTa3eLg2zXQkS5iSNKRERERCY4okRERERkgiNKRERERCYYlIiIiIhMMCgRERERmWBQIiIiIjLBoERERERkgkGJiIiIyMT/B5XlD7kFmxAXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(x, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(7, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_GNN = GNN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model_GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9490, Train Acc: 0.8467, Test Acc: 0.7368\n",
      "Epoch: 002, Loss: 0.4740, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 003, Loss: 0.5340, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 004, Loss: 0.3735, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 005, Loss: 0.2196, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 006, Loss: 0.5142, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 007, Loss: 0.4857, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 008, Loss: 0.3055, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 009, Loss: 0.4524, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 010, Loss: 0.4476, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 011, Loss: 0.5342, Train Acc: 0.8333, Test Acc: 0.6579\n",
      "Epoch: 012, Loss: 0.5596, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 013, Loss: 0.3178, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 014, Loss: 0.2386, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 015, Loss: 0.4332, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 016, Loss: 0.4300, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 017, Loss: 0.2258, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 018, Loss: 0.5739, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 019, Loss: 0.5215, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 020, Loss: 0.4666, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 021, Loss: 0.4196, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 022, Loss: 0.2460, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 023, Loss: 0.5348, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 024, Loss: 0.2630, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 025, Loss: 0.2301, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 026, Loss: 0.3052, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 027, Loss: 0.3402, Train Acc: 0.8400, Test Acc: 0.7105\n",
      "Epoch: 028, Loss: 0.5553, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 029, Loss: 0.3372, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 030, Loss: 0.4211, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 031, Loss: 0.6526, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 032, Loss: 0.4781, Train Acc: 0.8667, Test Acc: 0.6579\n",
      "Epoch: 033, Loss: 0.4565, Train Acc: 0.8333, Test Acc: 0.6579\n",
      "Epoch: 034, Loss: 0.2856, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 035, Loss: 0.4442, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 036, Loss: 0.4205, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 037, Loss: 0.3325, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 038, Loss: 0.4130, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 039, Loss: 0.4718, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 040, Loss: 0.1856, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 041, Loss: 0.4546, Train Acc: 0.8600, Test Acc: 0.7368\n",
      "Epoch: 042, Loss: 0.4555, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 043, Loss: 0.4883, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 044, Loss: 0.2849, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 045, Loss: 0.3077, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 046, Loss: 0.6104, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 047, Loss: 0.4648, Train Acc: 0.8400, Test Acc: 0.6579\n",
      "Epoch: 048, Loss: 0.3261, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 049, Loss: 0.3227, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 050, Loss: 0.3782, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 051, Loss: 0.4380, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 052, Loss: 0.4605, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 053, Loss: 0.2219, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 054, Loss: 0.4415, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 055, Loss: 0.3782, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 056, Loss: 0.5787, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 057, Loss: 0.6100, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 058, Loss: 0.4633, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 059, Loss: 0.2960, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 060, Loss: 0.3677, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 061, Loss: 0.4103, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 062, Loss: 0.2998, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 063, Loss: 0.5669, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 064, Loss: 0.4300, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 065, Loss: 0.4995, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 066, Loss: 0.3133, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 067, Loss: 0.2564, Train Acc: 0.8533, Test Acc: 0.6579\n",
      "Epoch: 068, Loss: 0.2257, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 069, Loss: 0.3002, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 070, Loss: 0.5772, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 071, Loss: 0.4985, Train Acc: 0.8400, Test Acc: 0.6579\n",
      "Epoch: 072, Loss: 0.5002, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 073, Loss: 0.3421, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 074, Loss: 0.2539, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 075, Loss: 0.1723, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 076, Loss: 0.3766, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 077, Loss: 0.1809, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 078, Loss: 0.4457, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 079, Loss: 0.3325, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 080, Loss: 0.2257, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 081, Loss: 0.2558, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 082, Loss: 0.1801, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 083, Loss: 0.5061, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 084, Loss: 0.3822, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 085, Loss: 0.3801, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 086, Loss: 0.3376, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 087, Loss: 0.1395, Train Acc: 0.8600, Test Acc: 0.7368\n",
      "Epoch: 088, Loss: 0.3546, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 089, Loss: 0.1893, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 090, Loss: 0.3770, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 091, Loss: 0.3366, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 092, Loss: 0.5208, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 093, Loss: 0.3948, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 094, Loss: 0.3507, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 095, Loss: 0.2562, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 096, Loss: 0.2029, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 097, Loss: 0.7322, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 098, Loss: 0.6214, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 099, Loss: 0.5474, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 100, Loss: 0.4520, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 101, Loss: 0.4731, Train Acc: 0.8533, Test Acc: 0.7368\n",
      "Epoch: 102, Loss: 0.1810, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 103, Loss: 0.4568, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 104, Loss: 0.2051, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 105, Loss: 0.2385, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 106, Loss: 0.4722, Train Acc: 0.8600, Test Acc: 0.7632\n",
      "Epoch: 107, Loss: 0.3829, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 108, Loss: 0.5029, Train Acc: 0.8600, Test Acc: 0.6579\n",
      "Epoch: 109, Loss: 0.2476, Train Acc: 0.8400, Test Acc: 0.6579\n",
      "Epoch: 110, Loss: 0.9061, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 111, Loss: 0.4234, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 112, Loss: 0.3105, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 113, Loss: 0.2681, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 114, Loss: 0.2330, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 115, Loss: 0.3610, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 116, Loss: 0.5481, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 117, Loss: 0.3815, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 118, Loss: 0.4474, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 119, Loss: 0.6253, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 120, Loss: 0.2292, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 121, Loss: 0.3898, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 122, Loss: 0.5291, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 123, Loss: 0.3150, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 124, Loss: 0.2392, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 125, Loss: 0.3614, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 126, Loss: 0.5144, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 127, Loss: 0.4692, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 128, Loss: 0.4469, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 129, Loss: 0.2794, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 130, Loss: 0.4296, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 131, Loss: 0.4325, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 132, Loss: 0.3615, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 133, Loss: 0.4800, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 134, Loss: 0.4293, Train Acc: 0.8333, Test Acc: 0.6842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Loss: 0.3342, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 136, Loss: 0.3528, Train Acc: 0.8467, Test Acc: 0.6842\n",
      "Epoch: 137, Loss: 0.3513, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 138, Loss: 0.4225, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 139, Loss: 0.6674, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 140, Loss: 0.5781, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 141, Loss: 0.5396, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 142, Loss: 0.4518, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 143, Loss: 0.4706, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 144, Loss: 0.3903, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 145, Loss: 0.4851, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 146, Loss: 0.3828, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 147, Loss: 0.2524, Train Acc: 0.8800, Test Acc: 0.7105\n",
      "Epoch: 148, Loss: 0.2910, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 149, Loss: 0.3635, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 150, Loss: 0.4667, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 151, Loss: 0.4974, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 152, Loss: 0.6563, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 153, Loss: 0.4298, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 154, Loss: 0.3753, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 155, Loss: 0.3387, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 156, Loss: 0.4399, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 157, Loss: 0.4616, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 158, Loss: 0.4538, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 159, Loss: 0.2849, Train Acc: 0.8800, Test Acc: 0.7105\n",
      "Epoch: 160, Loss: 0.2747, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 161, Loss: 0.2365, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 162, Loss: 0.4055, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 163, Loss: 0.2520, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 164, Loss: 0.4812, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 165, Loss: 0.2564, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 166, Loss: 0.4017, Train Acc: 0.8467, Test Acc: 0.7105\n",
      "Epoch: 167, Loss: 0.4372, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 168, Loss: 0.5181, Train Acc: 0.8800, Test Acc: 0.7105\n",
      "Epoch: 169, Loss: 0.3366, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 170, Loss: 0.5896, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 171, Loss: 0.3984, Train Acc: 0.8533, Test Acc: 0.6842\n",
      "Epoch: 172, Loss: 0.4688, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 173, Loss: 0.3796, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 174, Loss: 0.3039, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 175, Loss: 0.3968, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 176, Loss: 0.3700, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 177, Loss: 0.4957, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 178, Loss: 0.3745, Train Acc: 0.8333, Test Acc: 0.6842\n",
      "Epoch: 179, Loss: 0.4970, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 180, Loss: 0.6140, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 181, Loss: 0.3171, Train Acc: 0.8533, Test Acc: 0.7105\n",
      "Epoch: 182, Loss: 0.3592, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 183, Loss: 0.2026, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 184, Loss: 0.2867, Train Acc: 0.8600, Test Acc: 0.6842\n",
      "Epoch: 185, Loss: 0.3949, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 186, Loss: 0.5240, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 187, Loss: 0.5699, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 188, Loss: 0.2560, Train Acc: 0.8600, Test Acc: 0.7105\n",
      "Epoch: 189, Loss: 0.4293, Train Acc: 0.8800, Test Acc: 0.7105\n",
      "Epoch: 190, Loss: 0.1274, Train Acc: 0.8667, Test Acc: 0.7105\n",
      "Epoch: 191, Loss: 0.5823, Train Acc: 0.8533, Test Acc: 0.7368\n",
      "Epoch: 192, Loss: 0.5239, Train Acc: 0.8400, Test Acc: 0.6842\n",
      "Epoch: 193, Loss: 0.4291, Train Acc: 0.8667, Test Acc: 0.6842\n",
      "Epoch: 194, Loss: 0.2623, Train Acc: 0.8733, Test Acc: 0.6842\n",
      "Epoch: 195, Loss: 0.3840, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 196, Loss: 0.6386, Train Acc: 0.8667, Test Acc: 0.7368\n",
      "Epoch: 197, Loss: 0.3422, Train Acc: 0.8800, Test Acc: 0.7105\n",
      "Epoch: 198, Loss: 0.6508, Train Acc: 0.8733, Test Acc: 0.7105\n",
      "Epoch: 199, Loss: 0.5129, Train Acc: 0.8467, Test Acc: 0.7368\n",
      "Epoch: 200, Loss: 0.3934, Train Acc: 0.8400, Test Acc: 0.6842\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
